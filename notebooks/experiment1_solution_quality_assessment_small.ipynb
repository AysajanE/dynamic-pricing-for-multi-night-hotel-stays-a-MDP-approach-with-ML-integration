{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0a7314e-41c0-49f6-9537-4054d871fac2",
   "metadata": {},
   "source": [
    "# Experiment 1: DP vs. SAA Solution Quality Assessment\n",
    "## Small Scale Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1c8fe8-f123-45e5-8235-84e2f0b6dabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import time\n",
    "import logging\n",
    "from typing import Dict, List, Tuple\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# Import our custom modules\n",
    "from data_generator import TestConfiguration, create_test_instance\n",
    "from dynamic_pricing_algorithms import DynamicProgramming, StochasticApproximation\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41903976-462a-4e38-a88a-4b38d9623600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment1(num_trials: int = 5):\n",
    "    \"\"\"\n",
    "    Run Experiment 1: Solution Quality Assessment comparing SAA with DP.\n",
    "    \n",
    "    The experiment uses a small but realistic instance that allows for:\n",
    "    1. Exact solution via Dynamic Programming\n",
    "    2. Multiple trials of SAA to assess consistency\n",
    "    3. Statistical comparison of solution quality\n",
    "    \n",
    "    Args:\n",
    "        num_trials: Number of SAA trials to run for statistical significance\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing detailed experimental results\n",
    "    \"\"\"\n",
    "    logger.info(\"Starting Experiment 1: Solution Quality Assessment\")\n",
    "    \n",
    "    # Create test instance\n",
    "    config = TestConfiguration()\n",
    "    test_params = config.get_config(\n",
    "        test_type='minimal',\n",
    "        market_condition='standard',\n",
    "        discretization='coarse'\n",
    "    )\n",
    "    \n",
    "    # Set parameters for a tractable but meaningful test case\n",
    "    test_params.update({\n",
    "        'T': 10,  # 10 booking periods\n",
    "        'N': 5,   # 5-day service horizon\n",
    "        'C': 5,   # 5 rooms capacity\n",
    "        'price_min': 100,  # Reasonable price range\n",
    "        'price_max': 300,\n",
    "        'alpha': 0.1,     # Smoothing parameters for SAA\n",
    "        'beta': 0.1\n",
    "    })\n",
    "    \n",
    "    # Create instance with fixed seed for reproducibility\n",
    "    instance = create_test_instance(\n",
    "        demand_scenario='base',\n",
    "        market_condition='standard',\n",
    "        test_configuration=test_params,\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    logger.info(\"\\nTest Instance Configuration:\")\n",
    "    logger.info(f\"Booking Horizon (T): {test_params['T']} periods\")\n",
    "    logger.info(f\"Service Horizon (N): {test_params['N']} days\")\n",
    "    logger.info(f\"Room Capacity (C): {test_params['C']} rooms\")\n",
    "    logger.info(f\"Price Range: ${test_params['price_min']} - ${test_params['price_max']}\")\n",
    "    \n",
    "    # Solve using Dynamic Programming\n",
    "    logger.info(\"\\nSolving with Dynamic Programming...\")\n",
    "    dp = DynamicProgramming(instance)\n",
    "    start_time = time.time()\n",
    "    _, dp_revenue = dp.solve()\n",
    "    dp_time = time.time() - start_time\n",
    "    \n",
    "    # Configure SAA parameters\n",
    "    learning_params = {\n",
    "        'eta_0': 0.5,        # Initial learning rate\n",
    "        'gamma': 0.05,       # Learning rate decay\n",
    "        'eta_min': 0.001,    # Minimum learning rate\n",
    "        'max_epochs': 1000,\n",
    "        'batch_size': 64\n",
    "    }\n",
    "    \n",
    "    # Run multiple SAA trials\n",
    "    logger.info(\"\\nSolving with Stochastic Approximation...\")\n",
    "    saa_results = []\n",
    "    \n",
    "    for trial in range(num_trials):\n",
    "        logger.info(f\"\\nSAA Trial {trial + 1}/{num_trials}\")\n",
    "        saa = StochasticApproximation(instance, learning_params)\n",
    "        prices, revenue, solve_time = saa.solve()\n",
    "        \n",
    "        # Evaluate final solution with more samples\n",
    "        final_revenue = saa.evaluate(prices, num_samples=10000)\n",
    "        saa_results.append({\n",
    "            'revenue': final_revenue,\n",
    "            'time': solve_time\n",
    "        })\n",
    "        \n",
    "        logger.info(f\"Trial Revenue: ${final_revenue:.2f}\")\n",
    "        logger.info(f\"Trial Solution Time: {solve_time:.2f} seconds\")\n",
    "    \n",
    "    # Compute SAA statistics\n",
    "    saa_revenues = [r['revenue'] for r in saa_results]\n",
    "    saa_times = [r['time'] for r in saa_results]\n",
    "    \n",
    "    avg_saa_revenue = np.mean(saa_revenues)\n",
    "    std_saa_revenue = np.std(saa_revenues)\n",
    "    avg_saa_time = np.mean(saa_times)\n",
    "    \n",
    "    # Calculate optimality gap\n",
    "    gap_percentage = ((dp_revenue - avg_saa_revenue) / dp_revenue) * 100\n",
    "    \n",
    "    # Compute confidence interval for SAA revenue\n",
    "    confidence_level = 0.95\n",
    "    degrees_of_freedom = num_trials - 1\n",
    "    t_value = stats.t.ppf((1 + confidence_level) / 2, degrees_of_freedom)\n",
    "    margin_of_error = t_value * (std_saa_revenue / np.sqrt(num_trials))\n",
    "    \n",
    "    # Print comprehensive results\n",
    "    logger.info(\"\\nExperiment 1 Results Summary:\")\n",
    "    logger.info(f\"Dynamic Programming Revenue: ${dp_revenue:.2f}\")\n",
    "    logger.info(f\"DP Solution Time: {dp_time:.2f} seconds\")\n",
    "    logger.info(f\"\\nSAA Average Revenue: ${avg_saa_revenue:.2f} Â± ${margin_of_error:.2f}\")\n",
    "    logger.info(f\"SAA Revenue Std Dev: ${std_saa_revenue:.2f}\")\n",
    "    logger.info(f\"SAA Average Solution Time: {avg_saa_time:.2f} seconds\")\n",
    "    logger.info(f\"Optimality Gap: {gap_percentage:.2f}%\")\n",
    "    \n",
    "    return {\n",
    "        'dp_revenue': dp_revenue,\n",
    "        'dp_time': dp_time,\n",
    "        'saa_revenues': saa_revenues,\n",
    "        'saa_times': saa_times,\n",
    "        'avg_saa_revenue': avg_saa_revenue,\n",
    "        'std_saa_revenue': std_saa_revenue,\n",
    "        'gap_percentage': gap_percentage,\n",
    "        'confidence_interval': margin_of_error,\n",
    "        'instance_params': test_params,\n",
    "        'learning_params': learning_params\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bccd40-2d2a-4966-9d74-95e5fb378452",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    results = run_experiment1(num_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6dc9c8-7d36-449b-96ca-e7dd7de65923",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
