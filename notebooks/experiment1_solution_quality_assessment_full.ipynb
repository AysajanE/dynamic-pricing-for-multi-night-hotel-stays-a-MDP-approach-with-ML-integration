{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ca5fb6-dd2c-4a9d-b026-22c5c89a1063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List, Tuple\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import itertools\n",
    "\n",
    "from data_generator import TestConfiguration, create_test_instance\n",
    "from dynamic_pricing_algorithms import DynamicProgramming, StochasticApproximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a37d726-4dc8-4071-b6ae-fb84990d35e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382699f5-5411-4165-af56-6298f3150c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Experiment1Runner:\n",
    "    \"\"\"\n",
    "    Runner class for Experiment 1: Solution Quality Assessment\n",
    "    Compares SAA performance against optimal DP solution for small instances.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, output_dir: str = \"results/experiment1\"):\n",
    "        \"\"\"Initialize experiment runner with configuration.\"\"\"\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Define experiment parameters\n",
    "        self.T = 5  # Booking horizon\n",
    "        self.N = 3  # Service horizon\n",
    "        \n",
    "        # Define parameter ranges for test instances\n",
    "        self.capacity_levels = [3, 5, 7]  # Small capacities for tractable DP\n",
    "        self.demand_scenarios = ['low', 'base', 'high']\n",
    "        self.market_conditions = ['budget', 'standard', 'luxury']\n",
    "        \n",
    "        # SAA learning parameters\n",
    "        self.learning_params = {\n",
    "            'eta_0': 0.5,        # Initial learning rate\n",
    "            'gamma': 0.05,       # Learning rate decay\n",
    "            'eta_min': 0.001,    # Minimum learning rate\n",
    "            'max_epochs': 1000,  # Maximum training epochs\n",
    "            'batch_size': 64     # Mini-batch size\n",
    "        }\n",
    "        \n",
    "        # Statistical parameters\n",
    "        self.num_replications = 30  # Number of replications per configuration\n",
    "        self.confidence_level = 0.95\n",
    "        \n",
    "    def generate_test_instance(self, \n",
    "                             capacity: int,\n",
    "                             demand_scenario: str,\n",
    "                             market_condition: str,\n",
    "                             seed: int) -> Dict:\n",
    "        \"\"\"Generate a single test instance with specified parameters.\"\"\"\n",
    "        # Configure test parameters\n",
    "        config = TestConfiguration()\n",
    "        test_params = config.get_config(\n",
    "            test_type='minimal',\n",
    "            market_condition=market_condition,\n",
    "            discretization='standard'\n",
    "        )\n",
    "        \n",
    "        # Override with experiment-specific parameters\n",
    "        test_params.update({\n",
    "            'T': self.T,\n",
    "            'N': self.N,\n",
    "            'C': capacity\n",
    "        })\n",
    "        \n",
    "        # Create and return test instance\n",
    "        return create_test_instance(\n",
    "            demand_scenario=demand_scenario,\n",
    "            market_condition=market_condition,\n",
    "            test_configuration=test_params,\n",
    "            seed=seed\n",
    "        )\n",
    "    \n",
    "    def run_single_instance(self,\n",
    "                          instance: Dict,\n",
    "                          replication: int) -> Dict:\n",
    "        \"\"\"Run both DP and SAA on a single test instance.\"\"\"\n",
    "        try:\n",
    "            # Solve using Dynamic Programming\n",
    "            dp = DynamicProgramming(instance)\n",
    "            dp_start = datetime.now()\n",
    "            _, dp_revenue = dp.solve()\n",
    "            dp_time = (datetime.now() - dp_start).total_seconds()\n",
    "            \n",
    "            # Solve using SAA\n",
    "            saa = StochasticApproximation(instance, self.learning_params)\n",
    "            saa_start = datetime.now()\n",
    "            prices, saa_revenue, saa_time = saa.solve()\n",
    "            \n",
    "            # Compute revenue gap\n",
    "            revenue_gap = ((dp_revenue - saa_revenue) / dp_revenue) * 100\n",
    "            \n",
    "            return {\n",
    "                'capacity': instance['parameters'].C,\n",
    "                'demand_scenario': instance['scenario_info']['demand_scenario'],\n",
    "                'market_condition': instance['scenario_info']['market_condition'],\n",
    "                'replication': replication,\n",
    "                'dp_revenue': dp_revenue,\n",
    "                'dp_time': dp_time,\n",
    "                'saa_revenue': saa_revenue,\n",
    "                'saa_time': saa_time,\n",
    "                'revenue_gap': revenue_gap\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing instance: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def run_experiment(self, num_workers: int = 4) -> pd.DataFrame:\n",
    "        \"\"\"Run the complete experiment with all parameter combinations.\"\"\"\n",
    "        logger.info(\"Starting Experiment 1: Solution Quality Assessment\")\n",
    "        \n",
    "        # Generate parameter combinations\n",
    "        combinations = list(itertools.product(\n",
    "            self.capacity_levels,\n",
    "            self.demand_scenarios,\n",
    "            self.market_conditions,\n",
    "            range(self.num_replications)\n",
    "        ))\n",
    "        \n",
    "        # Initialize results storage\n",
    "        results = []\n",
    "        \n",
    "        # Run experiments in parallel\n",
    "        with ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "            future_to_params = {\n",
    "                executor.submit(\n",
    "                    self.run_single_instance,\n",
    "                    self.generate_test_instance(\n",
    "                        capacity=c,\n",
    "                        demand_scenario=d,\n",
    "                        market_condition=m,\n",
    "                        seed=100*r + 1\n",
    "                    ),\n",
    "                    r\n",
    "                ): (c, d, m, r) for c, d, m, r in combinations\n",
    "            }\n",
    "            \n",
    "            for future in future_to_params:\n",
    "                result = future.result()\n",
    "                if result is not None:\n",
    "                    results.append(result)\n",
    "        \n",
    "        # Convert results to DataFrame\n",
    "        results_df = pd.DataFrame(results)\n",
    "        \n",
    "        # Save raw results\n",
    "        results_df.to_csv(self.output_dir / 'raw_results.csv', index=False)\n",
    "        \n",
    "        return results_df\n",
    "    \n",
    "    def analyze_results(self, results_df: pd.DataFrame) -> Dict:\n",
    "        \"\"\"Perform statistical analysis on experiment results.\"\"\"\n",
    "        analysis = {}\n",
    "        \n",
    "        # Overall statistics\n",
    "        analysis['overall'] = {\n",
    "            'mean_revenue_gap': results_df['revenue_gap'].mean(),\n",
    "            'std_revenue_gap': results_df['revenue_gap'].std(),\n",
    "            'mean_dp_time': results_df['dp_time'].mean(),\n",
    "            'mean_saa_time': results_df['saa_time'].mean()\n",
    "        }\n",
    "        \n",
    "        # Paired t-test for revenue differences\n",
    "        t_stat, p_value = stats.ttest_rel(\n",
    "            results_df['dp_revenue'],\n",
    "            results_df['saa_revenue']\n",
    "        )\n",
    "        \n",
    "        analysis['statistical_tests'] = {\n",
    "            't_statistic': t_stat,\n",
    "            'p_value': p_value\n",
    "        }\n",
    "        \n",
    "        # Confidence intervals for revenue gap\n",
    "        ci = stats.t.interval(\n",
    "            self.confidence_level,\n",
    "            len(results_df) - 1,\n",
    "            loc=results_df['revenue_gap'].mean(),\n",
    "            scale=stats.sem(results_df['revenue_gap'])\n",
    "        )\n",
    "        \n",
    "        analysis['confidence_intervals'] = {\n",
    "            'revenue_gap_lower': ci[0],\n",
    "            'revenue_gap_upper': ci[1]\n",
    "        }\n",
    "        \n",
    "        # Analysis by capacity level\n",
    "        analysis['by_capacity'] = results_df.groupby('capacity').agg({\n",
    "            'revenue_gap': ['mean', 'std'],\n",
    "            'dp_time': 'mean',\n",
    "            'saa_time': 'mean'\n",
    "        }).to_dict()\n",
    "        \n",
    "        # Save analysis results\n",
    "        with open(self.output_dir / 'analysis_results.json', 'w') as f:\n",
    "            json.dump(analysis, f, indent=4)\n",
    "        \n",
    "        return analysis\n",
    "    \n",
    "    def create_visualizations(self, results_df: pd.DataFrame):\n",
    "        \"\"\"Create and save visualizations of experimental results.\"\"\"\n",
    "        # Set style\n",
    "        plt.style.use('seaborn')\n",
    "        \n",
    "        # 1. Revenue Comparison Bar Chart\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.barplot(data=results_df, x='capacity', y='dp_revenue', \n",
    "                   hue='demand_scenario', ci=95)\n",
    "        plt.title('DP Revenue by Capacity and Demand Scenario')\n",
    "        plt.xlabel('Capacity Level')\n",
    "        plt.ylabel('Revenue')\n",
    "        plt.savefig(self.output_dir / 'revenue_comparison.png')\n",
    "        plt.close()\n",
    "        \n",
    "        # 2. Revenue Gap Box Plot\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.boxplot(data=results_df, x='capacity', y='revenue_gap',\n",
    "                   hue='market_condition')\n",
    "        plt.title('Revenue Gap Distribution by Capacity and Market Condition')\n",
    "        plt.xlabel('Capacity Level')\n",
    "        plt.ylabel('Revenue Gap (%)')\n",
    "        plt.savefig(self.output_dir / 'revenue_gap_distribution.png')\n",
    "        plt.close()\n",
    "        \n",
    "        # 3. Solution Time Comparison\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        results_df_melted = pd.melt(results_df, \n",
    "                                   id_vars=['capacity'],\n",
    "                                   value_vars=['dp_time', 'saa_time'],\n",
    "                                   var_name='Algorithm',\n",
    "                                   value_name='Time (seconds)')\n",
    "        sns.boxplot(data=results_df_melted, x='capacity', y='Time (seconds)',\n",
    "                   hue='Algorithm')\n",
    "        plt.title('Solution Time Comparison')\n",
    "        plt.xlabel('Capacity Level')\n",
    "        plt.savefig(self.output_dir / 'solution_time_comparison.png')\n",
    "        plt.close()\n",
    "    \n",
    "    def generate_report(self, results_df: pd.DataFrame, analysis: Dict):\n",
    "        \"\"\"Generate a comprehensive report of experimental results.\"\"\"\n",
    "        report = []\n",
    "        report.append(\"# Experiment 1: Solution Quality Assessment Report\")\n",
    "        report.append(\"\\n## Overview\")\n",
    "        report.append(f\"- Total test instances: {len(results_df)}\")\n",
    "        report.append(f\"- Capacity levels: {self.capacity_levels}\")\n",
    "        report.append(f\"- Demand scenarios: {self.demand_scenarios}\")\n",
    "        report.append(f\"- Market conditions: {self.market_conditions}\")\n",
    "        report.append(f\"- Replications per configuration: {self.num_replications}\")\n",
    "        \n",
    "        report.append(\"\\n## Overall Results\")\n",
    "        report.append(f\"- Mean revenue gap: {analysis['overall']['mean_revenue_gap']:.2f}%\")\n",
    "        report.append(f\"- Revenue gap 95% CI: [{analysis['confidence_intervals']['revenue_gap_lower']:.2f}%, \"\n",
    "                     f\"{analysis['confidence_intervals']['revenue_gap_upper']:.2f}%]\")\n",
    "        report.append(f\"- Mean DP solution time: {analysis['overall']['mean_dp_time']:.2f} seconds\")\n",
    "        report.append(f\"- Mean SAA solution time: {analysis['overall']['mean_saa_time']:.2f} seconds\")\n",
    "        \n",
    "        report.append(\"\\n## Statistical Analysis\")\n",
    "        report.append(f\"- T-statistic: {analysis['statistical_tests']['t_statistic']:.4f}\")\n",
    "        report.append(f\"- P-value: {analysis['statistical_tests']['p_value']:.4f}\")\n",
    "        \n",
    "        report.append(\"\\n## Results by Capacity Level\")\n",
    "        for capacity in self.capacity_levels:\n",
    "            cap_data = analysis['by_capacity']\n",
    "            report.append(f\"\\nCapacity = {capacity}\")\n",
    "            report.append(f\"- Mean revenue gap: {cap_data['revenue_gap']['mean'][capacity]:.2f}%\")\n",
    "            report.append(f\"- Revenue gap std: {cap_data['revenue_gap']['std'][capacity]:.2f}%\")\n",
    "            report.append(f\"- Mean DP time: {cap_data['dp_time']['mean'][capacity]:.2f} seconds\")\n",
    "            report.append(f\"- Mean SAA time: {cap_data['saa_time']['mean'][capacity]:.2f} seconds\")\n",
    "        \n",
    "        # Save report\n",
    "        with open(self.output_dir / 'experiment_report.md', 'w') as f:\n",
    "            f.write('\\n'.join(report))\n",
    "    \n",
    "    def run_full_experiment(self, num_workers: int = 4):\n",
    "        \"\"\"Execute the complete experiment workflow.\"\"\"\n",
    "        logger.info(\"Starting full experiment execution\")\n",
    "        \n",
    "        # Run experiments\n",
    "        results_df = self.run_experiment(num_workers)\n",
    "        \n",
    "        # Analyze results\n",
    "        analysis = self.analyze_results(results_df)\n",
    "        \n",
    "        # Create visualizations\n",
    "        self.create_visualizations(results_df)\n",
    "        \n",
    "        # Generate report\n",
    "        self.generate_report(results_df, analysis)\n",
    "        \n",
    "        logger.info(\"Experiment execution completed\")\n",
    "        return results_df, analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982ee8e2-971f-411b-a639-94565cbda43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Add process safety for macOS\n",
    "    import multiprocessing\n",
    "    multiprocessing.set_start_method('spawn')\n",
    "    \n",
    "    # Run the complete experiment\n",
    "    experiment = Experiment1Runner()\n",
    "    try:\n",
    "        results, analysis = experiment.run_full_experiment(num_workers=4)\n",
    "        print(\"Experiment completed successfully\")\n",
    "        print(f\"Results saved to: {experiment.output_dir}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error running experiment: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32faeab5-c88e-4daf-995a-a7aaae5029f1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc28556d-4611-45d9-95e8-4b195c2c316a",
   "metadata": {},
   "source": [
    "# Experiment 1: Solution Quality Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ac013e-57bd-439c-8e05-7e4d679e747a",
   "metadata": {},
   "source": [
    "## Key Components and Design Decisions:\n",
    "\n",
    "1. **Experiment Structure**\n",
    "The implementation uses a class-based approach with `Experiment1Runner` to encapsulate all experiment functionality. This provides clear organization and makes the code maintainable and extensible.\n",
    "\n",
    "2. **Test Instance Generation**\n",
    "The code generates test instances using the provided `data_generator.py` script, varying:\n",
    "- Capacity levels (3, 5, 7 rooms)\n",
    "- Demand scenarios (low, base, high)\n",
    "- Market conditions (budget, standard, luxury)\n",
    "\n",
    "3. **Parallel Processing**\n",
    "The implementation uses Python's `ProcessPoolExecutor` to run experiments in parallel, significantly reducing execution time for the 30 replications per configuration.\n",
    "\n",
    "4. **Statistical Analysis**\n",
    "The code performs comprehensive statistical analysis including:\n",
    "- Paired t-tests comparing SAA and DP revenues\n",
    "- 95% confidence intervals for revenue gaps\n",
    "- Analysis by capacity level and demand scenario\n",
    "\n",
    "5. **Visualization and Reporting**\n",
    "The implementation creates three key visualizations:\n",
    "- Revenue comparison bar charts\n",
    "- Revenue gap box plots\n",
    "- Solution time comparisons\n",
    "\n",
    "6. **Results Management**\n",
    "All results are saved systematically:\n",
    "- Raw data in CSV format\n",
    "- Analysis results in JSON format\n",
    "- Visualizations as PNG files\n",
    "- Comprehensive report in Markdown format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3eb596a-f4bb-4d87-843f-c96d73f73431",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
