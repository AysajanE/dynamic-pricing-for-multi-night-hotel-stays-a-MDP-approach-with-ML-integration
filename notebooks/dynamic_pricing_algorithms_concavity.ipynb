{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18f6b588-b178-412d-a2ea-f7fa1b79e49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize_scalar\n",
    "from typing import Dict, Tuple, List\n",
    "import logging\n",
    "from dataclasses import dataclass\n",
    "import time\n",
    "from data_generator import TestConfiguration, create_test_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0f734e2-5701-4f84-bf8e-4d065efb0424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "257ae613-ad5e-4b52-b11a-916d9db4b612",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class DPState:\n",
    "    \"\"\"Immutable state representation for Dynamic Programming solution.\"\"\"\n",
    "    capacity: Tuple[int, ...]  # (capacity_day1, capacity_day2, capacity_day3)\n",
    "    time: int\n",
    "\n",
    "class DynamicProgramming:\n",
    "    \"\"\"\n",
    "    Optimized Dynamic Programming solution leveraging concavity properties\n",
    "    for hotel revenue optimization with multiple-night stays.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, instance: Dict):\n",
    "        \"\"\"Initialize using test instance from data_generator.\"\"\"\n",
    "        self.params = instance['parameters']\n",
    "        self.T = self.params.T\n",
    "        self.N = self.params.N\n",
    "        self.C = self.params.C\n",
    "        self.price_min = self.params.price_min\n",
    "        self.price_max = self.params.price_max\n",
    "        \n",
    "        self.booking_classes = instance['booking_classes']\n",
    "        self.arrival_probs = instance['arrival_probabilities']\n",
    "        self.price_sensitivity = instance['reservation_price_params']\n",
    "        \n",
    "        # Pre-compute class information for efficiency\n",
    "        self._precompute_class_info()\n",
    "        \n",
    "        # Initialize value function and policy\n",
    "        self.value_function: Dict[DPState, float] = {}\n",
    "        self.optimal_policy: Dict[DPState, Dict[int, float]] = {}\n",
    "        \n",
    "        logger.info(f\"Initialized DP solver with {len(self.booking_classes)} booking classes\")\n",
    "        \n",
    "    def _precompute_class_info(self):\n",
    "        \"\"\"Pre-compute booking class information for efficient lookup.\"\"\"\n",
    "        self.class_stays = {\n",
    "            (arr, dep): set(range(arr - 1, dep)) \n",
    "            for arr, dep in self.booking_classes\n",
    "        }\n",
    "        self.stay_lengths = {\n",
    "            (arr, dep): dep - arr + 1 \n",
    "            for arr, dep in self.booking_classes\n",
    "        }\n",
    "    def _compute_purchase_probability(self, price: float, epsilon: float) -> float:\n",
    "        \"\"\"\n",
    "        Compute purchase probability using linear demand function.\n",
    "        F̄_b(p_t^b) = 1 - ε_b * p_t^b\n",
    "        \"\"\"\n",
    "        return max(0.0, min(1.0, 1.0 - epsilon * price))    \n",
    "    \n",
    "    def _optimize_state_prices(self, state: DPState) -> Tuple[float, Dict[int, float]]:\n",
    "        \"\"\"\n",
    "        Optimize prices for current state leveraging concavity.\n",
    "        \n",
    "        Uses gradient-based optimization for each day's price within bounds,\n",
    "        taking advantage of the problem's concavity property.\n",
    "        \"\"\"\n",
    "        optimal_prices = {}\n",
    "        total_value = 0.0\n",
    "        \n",
    "        # Initialize with current prices at midpoint\n",
    "        current_prices = {i: (self.price_min + self.price_max) / 2 \n",
    "                        for i in range(self.N)}\n",
    "        \n",
    "        # Optimize each day's price separately using concavity\n",
    "        for day in range(self.N):\n",
    "            def negative_revenue(price):\n",
    "                \"\"\"Objective function for single-day price optimization.\"\"\"\n",
    "                current_prices[day] = price\n",
    "                return -self._compute_expected_value(state, current_prices)\n",
    "            \n",
    "            # Use scipy's minimize_scalar with bounds\n",
    "            result = minimize_scalar(\n",
    "                negative_revenue,\n",
    "                bounds=(self.price_min, self.price_max),\n",
    "                method='bounded'\n",
    "            )\n",
    "            \n",
    "            optimal_prices[day] = result.x\n",
    "            total_value = -result.fun\n",
    "        \n",
    "        return total_value, optimal_prices\n",
    "    \n",
    "    def _compute_expected_value(self, state: DPState, prices: Dict[int, float]) -> float:\n",
    "        \"\"\"\n",
    "        Compute expected value for state-prices pair with efficient implementation.\n",
    "        \"\"\"\n",
    "        value = 0.0\n",
    "        current_probs = self.arrival_probs[state.time]\n",
    "        \n",
    "        # Handle no arrival case\n",
    "        no_arrival_prob = 1.0 - sum(current_probs.values())\n",
    "        if no_arrival_prob > 0:\n",
    "            next_state = DPState(capacity=state.capacity, time=state.time + 1)\n",
    "            value += no_arrival_prob * self.value_function[next_state]\n",
    "        \n",
    "        # Process each possible booking request efficiently\n",
    "        for (arrival, departure), arrival_prob in current_probs.items():\n",
    "            if arrival_prob <= 0:\n",
    "                continue\n",
    "                \n",
    "            stay_nights = self.class_stays[(arrival, departure)]\n",
    "            has_capacity = all(state.capacity[day] > 0 for day in stay_nights)\n",
    "            \n",
    "            if has_capacity:\n",
    "                # Calculate average price and acceptance probability\n",
    "                stay_prices = [prices[day] for day in stay_nights]\n",
    "                avg_price = sum(stay_prices) / self.stay_lengths[(arrival, departure)]\n",
    "                \n",
    "                eps = self.price_sensitivity[(arrival, departure)]\n",
    "                accept_prob = self._compute_purchase_probability(avg_price, eps)\n",
    "                \n",
    "                if accept_prob > 0:\n",
    "                    # Handle acceptance case\n",
    "                    next_capacity = list(state.capacity)\n",
    "                    for day in stay_nights:\n",
    "                        next_capacity[day] -= 1\n",
    "                    \n",
    "                    next_state = DPState(\n",
    "                        capacity=tuple(next_capacity), \n",
    "                        time=state.time + 1\n",
    "                    )\n",
    "                    immediate_revenue = sum(stay_prices)\n",
    "                    future_value = self.value_function[next_state]\n",
    "                    \n",
    "                    value += arrival_prob * accept_prob * (immediate_revenue + future_value)\n",
    "                \n",
    "                # Handle rejection case\n",
    "                if accept_prob < 1:\n",
    "                    reject_prob = 1 - accept_prob\n",
    "                    next_state = DPState(capacity=state.capacity, time=state.time + 1)\n",
    "                    value += arrival_prob * reject_prob * self.value_function[next_state]\n",
    "            else:\n",
    "                # Handle no capacity case\n",
    "                next_state = DPState(capacity=state.capacity, time=state.time + 1)\n",
    "                value += arrival_prob * self.value_function[next_state]\n",
    "        \n",
    "        return value\n",
    "    \n",
    "    def solve(self) -> Tuple[Dict[Tuple[int, ...], Dict[int, float]], float]:\n",
    "        \"\"\"\n",
    "        Solve the DP problem efficiently using concavity properties.\n",
    "        \n",
    "        Returns:\n",
    "            Tuple of (optimal_policy, optimal_value)\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        logger.info(\"Starting optimized DP solution\")\n",
    "        \n",
    "        # Initialize boundary conditions\n",
    "        self._initialize_boundary_conditions()\n",
    "        \n",
    "        # Backward induction with efficient price optimization\n",
    "        for t in range(self.T, 0, -1):\n",
    "            period_start = time.time()\n",
    "            states_processed = 0\n",
    "            \n",
    "            for capacity in self._generate_capacity_vectors():\n",
    "                state = DPState(capacity=capacity, time=t)\n",
    "                optimal_value, optimal_prices = self._optimize_state_prices(state)\n",
    "                \n",
    "                self.value_function[state] = optimal_value\n",
    "                self.optimal_policy[state] = optimal_prices\n",
    "                states_processed += 1\n",
    "            \n",
    "            period_time = time.time() - period_start\n",
    "            logger.info(\n",
    "                f\"Processed period {t}: {states_processed} states \"\n",
    "                f\"in {period_time:.2f} seconds\"\n",
    "            )\n",
    "        \n",
    "        # Extract initial state value and policy\n",
    "        initial_state = DPState(\n",
    "            capacity=tuple(self.C for _ in range(self.N)),\n",
    "            time=1\n",
    "        )\n",
    "        optimal_value = self.value_function[initial_state]\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        logger.info(\n",
    "            f\"DP solution completed in {total_time:.2f} seconds. \"\n",
    "            f\"Optimal value: {optimal_value:.2f}\"\n",
    "        )\n",
    "        \n",
    "        return self.optimal_policy, optimal_value\n",
    "    \n",
    "    def _initialize_boundary_conditions(self):\n",
    "        \"\"\"Initialize boundary conditions efficiently.\"\"\"\n",
    "        logger.info(\"Initializing boundary conditions\")\n",
    "        \n",
    "        # Terminal period conditions\n",
    "        for capacity in self._generate_capacity_vectors():\n",
    "            terminal_state = DPState(capacity=capacity, time=self.T + 1)\n",
    "            self.value_function[terminal_state] = 0.0\n",
    "            \n",
    "            # Zero capacity conditions for all periods\n",
    "            if sum(capacity) == 0:\n",
    "                for t in range(1, self.T + 2):\n",
    "                    state = DPState(capacity=capacity, time=t)\n",
    "                    self.value_function[state] = 0.0\n",
    "                    \n",
    "    def _generate_capacity_vectors(self) -> List[Tuple[int, ...]]:\n",
    "        \"\"\"\n",
    "        Generate capacity vectors efficiently using numpy.\n",
    "        \"\"\"\n",
    "        capacities = np.array(\n",
    "            np.meshgrid(\n",
    "                *[range(self.C + 1) for _ in range(self.N)]\n",
    "            )\n",
    "        ).T.reshape(-1, self.N)\n",
    "        \n",
    "        return [tuple(cap) for cap in capacities]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     def solve(self) -> Tuple[Dict[Tuple[int, ...], Dict[int, float]], float]:\n",
    "#         \"\"\"Solve the DP problem and return value functions and optimal policy.\"\"\"\n",
    "#         logger.info(\"Starting DP solution\")\n",
    "        \n",
    "#         # Initialize boundary conditions\n",
    "#         self._initialize_boundary_conditions()\n",
    "        \n",
    "#         # Backward induction\n",
    "#         for t in range(self.T, 0, -1):\n",
    "#             logger.info(f\"Processing time period {t}\")\n",
    "#             for capacity in self._generate_capacity_vectors():\n",
    "#                 state = DPState(capacity=capacity, time=t)\n",
    "#                 optimal_value, optimal_prices = self._compute_optimal_decision(state)\n",
    "#                 self.value_function[state] = optimal_value\n",
    "                \n",
    "#                 # Store policy as dictionary mapping day to price\n",
    "#                 self.optimal_policy[state] = {\n",
    "#                     i+1: price for i, price in enumerate(optimal_prices)\n",
    "#                 }\n",
    "        \n",
    "#         # Extract and format results for capacity = 5\n",
    "#         results = {}\n",
    "#         for state, prices in self.optimal_policy.items():\n",
    "#             if state.capacity[0] == 5:  # Only for first day capacity = 5\n",
    "#                 results[state.capacity] = prices\n",
    "        \n",
    "#         # Get optimal value for initial state\n",
    "#         initial_state = DPState(\n",
    "#             capacity=tuple(self.C for _ in range(self.N)),\n",
    "#             time=1\n",
    "#         )\n",
    "#         optimal_value = self.value_function[initial_state]\n",
    "        \n",
    "#         return results, optimal_value\n",
    "    \n",
    "#     def _initialize_boundary_conditions(self):\n",
    "#         \"\"\"Initialize boundary conditions.\"\"\"\n",
    "#         for capacity in self._generate_capacity_vectors():\n",
    "#             # Terminal period conditions\n",
    "#             terminal_state = DPState(capacity=capacity, time=self.T + 1)\n",
    "#             self.value_function[terminal_state] = 0.0\n",
    "            \n",
    "#             # Zero capacity conditions for all periods\n",
    "#             if sum(capacity) == 0:\n",
    "#                 for t in range(1, self.T + 2):\n",
    "#                     state = DPState(capacity=capacity, time=t)\n",
    "#                     self.value_function[state] = 0.0\n",
    "    \n",
    "#     def _compute_optimal_decision(self, state: DPState) -> Tuple[float, Tuple[float, ...]]:\n",
    "#         \"\"\"Compute optimal value and prices for a state.\"\"\"\n",
    "#         max_value = float('-inf')\n",
    "#         optimal_prices = self.price_levels[0:self.N]  # Default to minimum prices\n",
    "        \n",
    "#         for prices in self.price_combinations:\n",
    "#             value = self._compute_expected_value(state, prices)\n",
    "#             if value > max_value:\n",
    "#                 max_value = value\n",
    "#                 optimal_prices = prices\n",
    "        \n",
    "#         return max_value, optimal_prices\n",
    "    \n",
    "#     def _compute_expected_value(self, state: DPState, prices: Tuple[float, ...]) -> float:\n",
    "#         \"\"\"Compute expected value for state-prices pair.\"\"\"\n",
    "#         value = 0.0\n",
    "#         current_probs = self.arrival_probs[state.time]\n",
    "        \n",
    "#         # No arrival case\n",
    "#         no_arrival_prob = 1.0 - sum(current_probs.values())\n",
    "#         if no_arrival_prob > 0:\n",
    "#             next_state = DPState(capacity=state.capacity, time=state.time + 1)\n",
    "#             value += no_arrival_prob * self.value_function[next_state]\n",
    "        \n",
    "#         # For each possible booking request\n",
    "#         for (arrival, departure), arrival_prob in current_probs.items():\n",
    "#             if arrival_prob <= 0:\n",
    "#                 continue\n",
    "                \n",
    "#             stay_nights = self.class_stays[(arrival, departure)]\n",
    "#             has_capacity = all(state.capacity[day] > 0 for day in stay_nights)\n",
    "            \n",
    "#             if has_capacity:\n",
    "#                 # Calculate average price and acceptance probability\n",
    "#                 stay_prices = [prices[day] for day in stay_nights]\n",
    "#                 avg_price = sum(stay_prices) / self.stay_lengths[(arrival, departure)]\n",
    "                \n",
    "#                 eps = self.price_sensitivity[(arrival, departure)]\n",
    "#                 accept_prob = max(0, 1 - eps * avg_price)\n",
    "                \n",
    "#                 if accept_prob > 0:\n",
    "#                     # Acceptance case\n",
    "#                     next_capacity = list(state.capacity)\n",
    "#                     for day in stay_nights:\n",
    "#                         next_capacity[day] -= 1\n",
    "                    \n",
    "#                     next_state = DPState(capacity=tuple(next_capacity), time=state.time + 1)\n",
    "#                     immediate_revenue = sum(stay_prices)\n",
    "#                     future_value = self.value_function[next_state]\n",
    "                    \n",
    "#                     value += arrival_prob * accept_prob * (immediate_revenue + future_value)\n",
    "                \n",
    "#                 # Rejection case\n",
    "#                 if accept_prob < 1:\n",
    "#                     reject_prob = 1 - accept_prob\n",
    "#                     next_state = DPState(capacity=state.capacity, time=state.time + 1)\n",
    "#                     value += arrival_prob * reject_prob * self.value_function[next_state]\n",
    "#             else:\n",
    "#                 # No capacity case\n",
    "#                 next_state = DPState(capacity=state.capacity, time=state.time + 1)\n",
    "#                 value += arrival_prob * self.value_function[next_state]\n",
    "        \n",
    "#         return value\n",
    "    \n",
    "#     def _generate_capacity_vectors(self) -> List[Tuple[int, ...]]:\n",
    "#         \"\"\"Generate all possible capacity vectors.\"\"\"\n",
    "#         return [tuple(cap) for cap in itertools.product(range(self.C + 1), repeat=self.N)]\n",
    "\n",
    "class StochasticApproximation:\n",
    "    \"\"\"\n",
    "    Implementation of the Stochastic Approximation Algorithm for hotel dynamic pricing.\n",
    "    \n",
    "    This implementation follows the exact methodology described in the theoretical framework,\n",
    "    incorporating smoothed decision functions and proper gradient calculations.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, instance: Dict, learning_params: Dict = None):\n",
    "        \"\"\"\n",
    "        Initialize the SAA algorithm with problem instance and learning parameters.\n",
    "        \n",
    "        Args:\n",
    "            instance: Dictionary containing problem parameters and data\n",
    "            learning_params: Dictionary containing learning rate parameters:\n",
    "                - eta_0: Initial learning rate\n",
    "                - gamma: Learning rate decay parameter\n",
    "                - eta_min: Minimum learning rate\n",
    "                - max_epochs: Maximum number of training epochs\n",
    "                - batch_size: Mini-batch size for gradient computation\n",
    "        \"\"\"\n",
    "        # Extract instance parameters\n",
    "        self.params = instance['parameters']\n",
    "        self.booking_classes = instance['booking_classes']\n",
    "        self.arrival_probs = instance['arrival_probabilities']\n",
    "        self.epsilon = instance['reservation_price_params']\n",
    "        \n",
    "        # Set learning parameters\n",
    "        default_learning_params = {\n",
    "            'eta_0': 0.1,\n",
    "            'gamma': 0.1,\n",
    "            'eta_min': 0.001,\n",
    "            'max_epochs': 1000,\n",
    "            'batch_size': 32\n",
    "        }\n",
    "        self.learning_params = {**default_learning_params, **(learning_params or {})}\n",
    "        \n",
    "        # Initialize smoothing parameters from instance\n",
    "        self.alpha = self.params.alpha  # Price acceptance smoothing\n",
    "        self.beta = self.params.beta    # Capacity smoothing\n",
    "        \n",
    "        # Initialize prices and precompute class information\n",
    "        self.prices = self._initialize_prices()\n",
    "        self._precompute_class_info()\n",
    "        \n",
    "        logger.info(f\"Initialized SAA with {len(self.booking_classes)} booking classes\")\n",
    "    \n",
    "    def _initialize_prices(self) -> Dict[int, np.ndarray]:\n",
    "        \"\"\"Initialize price vectors for each booking period.\"\"\"\n",
    "        return {t: np.full(self.params.N, (self.params.price_min + self.params.price_max) / 2)\n",
    "                for t in range(1, self.params.T + 1)}\n",
    "    \n",
    "    def _precompute_class_info(self):\n",
    "        \"\"\"Precompute booking class information for efficient computation.\"\"\"\n",
    "        self.class_stays = {}\n",
    "        self.stay_lengths = {}\n",
    "        for arrival, departure in self.booking_classes:\n",
    "            self.class_stays[(arrival, departure)] = list(range(arrival - 1, departure))\n",
    "            self.stay_lengths[(arrival, departure)] = departure - arrival + 1\n",
    "    \n",
    "    def _compute_smoothed_decision(self, \n",
    "                                 price_bt: float,\n",
    "                                 qt: float,\n",
    "                                 xt: np.ndarray,\n",
    "                                 stay_nights: List[int]) -> float:\n",
    "        \"\"\"\n",
    "        Compute smoothed decision function value.\n",
    "        \n",
    "        Args:\n",
    "            price_bt: Average price for booking class b at time t\n",
    "            qt: Customer's reservation price\n",
    "            xt: Current capacity vector\n",
    "            stay_nights: List of nights required for the stay\n",
    "            \n",
    "        Returns:\n",
    "            Smoothed decision function value\n",
    "        \"\"\"\n",
    "        # Price acceptance smoothing\n",
    "        sp = 1 / (1 + np.exp(-self.alpha * (qt - price_bt)))\n",
    "        \n",
    "        # Capacity smoothing for each required night\n",
    "        sx = np.prod([1 / (1 + np.exp(-self.beta * (xt[i] - 1))) for i in stay_nights])\n",
    "        \n",
    "        return sp * sx\n",
    "    \n",
    "    def _compute_decision_gradients(self,\n",
    "                               i: int,\n",
    "                               price_bt: float,\n",
    "                               qt: float,\n",
    "                               xt: np.ndarray,\n",
    "                               stay_nights: List[int],\n",
    "                               Lb: int) -> Tuple[float, float]:\n",
    "        \"\"\"\n",
    "        Compute gradients of the decision function with respect to price and capacity.\n",
    "        \n",
    "        Args:\n",
    "            i: Index of the day\n",
    "            price_bt: Average price for booking class b_t\n",
    "            qt: Customer's reservation price\n",
    "            xt: Current capacity vector\n",
    "            stay_nights: List of nights required for the stay\n",
    "            Lb: Length of stay\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (∂ũ/∂p_(t,i), ∂ũ/∂x_(t,i))\n",
    "        \"\"\"\n",
    "        if i not in stay_nights:\n",
    "            return 0.0, 0.0\n",
    "            \n",
    "        # Compute common terms\n",
    "        sp = 1 / (1 + np.exp(-self.alpha * (qt - price_bt)))\n",
    "        sx_prod = np.prod([1 / (1 + np.exp(-self.beta * (xt[j] - 1))) \n",
    "                          for j in stay_nights])\n",
    "        \n",
    "        # Compute price gradient\n",
    "        du_dp = -(self.alpha / Lb) * sp * (1 - sp) * sx_prod\n",
    "        \n",
    "        # Compute capacity gradient\n",
    "        sx_i = 1 / (1 + np.exp(-self.beta * (xt[i] - 1)))\n",
    "        du_dx = self.beta * sp * (1 - sx_i) * sx_prod\n",
    "        \n",
    "        return du_dp, du_dx\n",
    "    \n",
    "    def _compute_immediate_revenue(self,\n",
    "                                 bt: Tuple[int, int],\n",
    "                                 price_bt: float,\n",
    "                                 ut: float) -> float:\n",
    "        \"\"\"\n",
    "        Compute immediate revenue for an accepted booking.\n",
    "        \n",
    "        Args:\n",
    "            bt: Booking class tuple (arrival, departure)\n",
    "            price_bt: Average price for the stay\n",
    "            ut: Decision function value\n",
    "            \n",
    "        Returns:\n",
    "            Immediate revenue\n",
    "        \"\"\"\n",
    "        Lb = self.stay_lengths[bt]\n",
    "        return Lb * price_bt * ut\n",
    "    \n",
    "    def _compute_revenue_gradients(self,\n",
    "                               i: int,\n",
    "                               price_bt: float,\n",
    "                               qt: float,\n",
    "                               xt: np.ndarray,\n",
    "                               stay_nights: List[int],\n",
    "                               Lb: int) -> Tuple[float, float]:\n",
    "        \"\"\"\n",
    "        Compute gradients of immediate revenue with respect to price and capacity.\n",
    "        \n",
    "        For price gradient (i ∈ N^(b_t)):\n",
    "        ∂R_t/∂p_(t,i) = ũ^(b_t)_t + Lb * p^(b_t)_t * ∂ũ^(b_t)_t/∂p_(t,i)\n",
    "        \n",
    "        For capacity gradient (i ∈ N^(b_t)):\n",
    "        ∂R_t/∂x_(t,i) = Lb * p^(b_t)_t * ∂ũ^(b_t)_t/∂x_(t,i)\n",
    "        \n",
    "        Args:\n",
    "            i: Index of the day\n",
    "            price_bt: Average price for booking class b_t\n",
    "            qt: Customer's reservation price\n",
    "            xt: Current capacity vector\n",
    "            stay_nights: List of nights required for the stay\n",
    "            Lb: Length of stay\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (∂R_t/∂p_(t,i), ∂R_t/∂x_(t,i))\n",
    "        \"\"\"\n",
    "        if i not in stay_nights:\n",
    "            return 0.0, 0.0\n",
    "            \n",
    "        # Compute base decision function value\n",
    "        ut = self._compute_smoothed_decision(price_bt, qt, xt, stay_nights)\n",
    "        \n",
    "        # Compute decision function gradients\n",
    "        du_dp, du_dx = self._compute_decision_gradients(i, price_bt, qt, xt, stay_nights, Lb)\n",
    "        \n",
    "        # Compute revenue gradients\n",
    "        dR_dp = ut + Lb * price_bt * du_dp  # Price gradient includes both immediate and derivative terms\n",
    "        dR_dx = Lb * price_bt * du_dx       # Capacity gradient only includes derivative term\n",
    "        \n",
    "        return dR_dp, dR_dx\n",
    "    \n",
    "    def _generate_sample_path(self) -> List[Tuple]:\n",
    "        \"\"\"\n",
    "        Generate a sample path of customer arrivals and reservation prices.\n",
    "        \n",
    "        The sample path generation follows the two-step process from the theoretical framework:\n",
    "        1. For each time period, determine if a customer arrives based on total arrival probability\n",
    "        2. If an arrival occurs, select the booking class and randomly sample reservation price\n",
    "        \n",
    "        Returns:\n",
    "            List of (time, booking_class, reservation_price) tuples, where booking_class\n",
    "            and reservation_price are None if no arrival occurs in that time period\n",
    "        \"\"\"\n",
    "        path = []\n",
    "        for t in range(1, self.params.T + 1):\n",
    "            # Get arrival probabilities for current time period\n",
    "            probs = self.arrival_probs[t]\n",
    "            arrival_prob = np.random.random()\n",
    "            total_prob = sum(probs.values())\n",
    "            \n",
    "            if arrival_prob < total_prob:\n",
    "                # Customer arrives - select booking class\n",
    "                classes = list(probs.keys())\n",
    "                probabilities = [probs[c] for c in classes]\n",
    "                \n",
    "                # Normalize probabilities for class selection\n",
    "                normalized_probabilities = [p/total_prob for p in probabilities]\n",
    "                bt = classes[np.random.choice(len(classes), p=np.array(normalized_probabilities))]\n",
    "                \n",
    "                # Generate reservation price based on class-specific epsilon\n",
    "                eps = self.epsilon[bt]\n",
    "                u = np.random.random()\n",
    "                qt = u / eps    # Use inverse transform method for CDF: epsilon*p\n",
    "                \n",
    "                path.append((t, bt, qt))\n",
    "            else:\n",
    "                # No arrival in this time period\n",
    "                path.append((t, None, None))\n",
    "        \n",
    "        return path\n",
    "    \n",
    "    def _forward_pass(self, sample_path: List[Tuple]) -> Tuple[Dict, Dict, Dict]:\n",
    "        \"\"\"\n",
    "        Perform forward pass through the sample path following Algorithm Phase I.b.2.\n",
    "        \n",
    "        Args:\n",
    "            sample_path: List of (time, booking_class, reservation_price) tuples\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (revenues, decision_values, capacities) where each is a dictionary\n",
    "            mapping time periods to their respective values\n",
    "        \"\"\"\n",
    "        # Initialize storage for algorithm outputs\n",
    "        revenues = {}          # Store R_t for each t\n",
    "        decision_values = {}   # Store ũ_t^(b_t) for each t\n",
    "        capacities = {1: np.full(self.params.N, self.params.C, dtype=np.float64)}  # Initialize x_1 with float type for training\n",
    "        \n",
    "        for t, bt, qt in sample_path:\n",
    "            if bt is not None:\n",
    "                # Extract booking class information\n",
    "                stay_nights = self.class_stays[bt]\n",
    "                Lb = self.stay_lengths[bt]\n",
    "                \n",
    "                # Compute average price for the stay\n",
    "                stay_prices = [self.prices[t][i] for i in stay_nights]\n",
    "                price_bt = sum(stay_prices) / Lb\n",
    "                \n",
    "                # Compute smoothed decision function\n",
    "                ut = self._compute_smoothed_decision(price_bt, qt, capacities[t], stay_nights)\n",
    "                \n",
    "                # Compute immediate revenue\n",
    "                rt = self._compute_immediate_revenue(bt, price_bt, ut)\n",
    "                \n",
    "                # Update capacity\n",
    "                next_capacity = capacities[t].copy()\n",
    "                for i in stay_nights:\n",
    "                    next_capacity[i] -= ut\n",
    "                \n",
    "                # Store values\n",
    "                revenues[t] = rt\n",
    "                decision_values[t] = ut\n",
    "                capacities[t + 1] = next_capacity\n",
    "                \n",
    "            else:\n",
    "                # No arrival case\n",
    "                revenues[t] = 0\n",
    "                decision_values[t] = 0\n",
    "                capacities[t + 1] = capacities[t].copy()\n",
    "        \n",
    "        return revenues, decision_values, capacities\n",
    "    \n",
    "    def _backward_pass(\n",
    "            self,\n",
    "            revenues: Dict[int, float],\n",
    "            decision_values: Dict[int, float],\n",
    "            capacities: Dict[int, np.ndarray],\n",
    "            sample_path: List[Tuple]) -> Dict[int, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Perform backward pass to compute gradients following Algorithm Phase I.b.3.\n",
    "        \n",
    "        Args:\n",
    "            revenues: Dictionary mapping t to R_t\n",
    "            decision_values: Dictionary mapping t to ũ_t^(b_t)\n",
    "            capacities: Dictionary mapping t to x_t\n",
    "            sample_path: List of (time, booking_class, reservation_price) tuples\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary mapping time periods to gradient accumulators ∇_p^(t,i)\n",
    "        \"\"\"\n",
    "        # Initialize gradient accumulators and terminal conditions\n",
    "        gradient_accumulators = {t: np.zeros(self.params.N) \n",
    "                               for t in range(1, self.params.T + 1)}\n",
    "        dJ_dx_next = np.zeros(self.params.N)  # ∂J/∂x_(T+1,i) = 0\n",
    "        \n",
    "        # Backward pass from T to 1\n",
    "        for t in range(self.params.T, 0, -1):\n",
    "            t_idx = t - 1  # Convert to 0-based index for sample path\n",
    "            _, bt, qt = sample_path[t_idx]\n",
    "            \n",
    "            if bt is not None:\n",
    "                # Extract booking class information\n",
    "                stay_nights = self.class_stays[bt]\n",
    "                Lb = self.stay_lengths[bt]\n",
    "                \n",
    "                # Compute average price for the stay\n",
    "                stay_prices = [self.prices[t][i] for i in stay_nights]\n",
    "                price_bt = sum(stay_prices) / Lb\n",
    "                \n",
    "                # Get stored values\n",
    "                # ut = decision_values[t]\n",
    "                xt = capacities[t]\n",
    "                \n",
    "                # Initialize gradient arrays for current time period\n",
    "                dJ_dp = np.zeros(self.params.N)\n",
    "                dJ_dx = np.zeros(self.params.N)\n",
    "                \n",
    "                # Compute gradients for each day\n",
    "                for i in range(self.params.N):\n",
    "                    # Compute immediate revenue gradients\n",
    "                    dR_dp, dR_dx = self._compute_revenue_gradients(\n",
    "                        i, price_bt, qt, xt, stay_nights, Lb)\n",
    "                    \n",
    "                    # Compute decision function gradients\n",
    "                    du_dp, du_dx = self._compute_decision_gradients(\n",
    "                        i, price_bt, qt, xt, stay_nights, Lb)\n",
    "                    \n",
    "                    # Sum gradient terms for nights in the stay\n",
    "                    gradient_sum_dp = 0.0\n",
    "                    gradient_sum_dx = 0.0\n",
    "                    for k in stay_nights:\n",
    "                        gradient_sum_dp += du_dp * dJ_dx_next[k]\n",
    "                        gradient_sum_dx += du_dx * dJ_dx_next[k]\n",
    "                    \n",
    "                    # Update total derivatives\n",
    "                    dJ_dp[i] = dR_dp - gradient_sum_dp\n",
    "                    dJ_dx[i] = dR_dx + dJ_dx_next[i] - gradient_sum_dx\n",
    "                \n",
    "                # Accumulate gradients\n",
    "                gradient_accumulators[t] += dJ_dp\n",
    "                \n",
    "            else:\n",
    "                # No arrival case - only capacity gradients persist\n",
    "                dJ_dx = dJ_dx_next.copy()\n",
    "            \n",
    "            # Update dJ_dx_next for next iteration\n",
    "            dJ_dx_next = dJ_dx\n",
    "            \n",
    "        return gradient_accumulators\n",
    "    \n",
    "    def _update_prices(self, gradients: Dict[int, np.ndarray], learning_rate: float):\n",
    "        \"\"\"Update prices using computed gradients.\"\"\"\n",
    "        for t in range(1, self.params.T + 1):\n",
    "            self.prices[t] += learning_rate * gradients[t]\n",
    "            # Project prices to feasible range\n",
    "            self.prices[t] = np.clip(self.prices[t], \n",
    "                                   self.params.price_min, \n",
    "                                   self.params.price_max)\n",
    "    \n",
    "#     def solve(self) -> Tuple[Dict[int, np.ndarray], float, float]:\n",
    "#         \"\"\"\n",
    "#         Execute the SAA algorithm with proper gradient-based optimization and convergence checking.\n",
    "        \n",
    "#         Implements Phase I.c: Price Update and Convergence Check from the theoretical framework.\n",
    "        \n",
    "#         Returns:\n",
    "#             Tuple of (final_prices, final_revenue, solve_time)\n",
    "#         \"\"\"\n",
    "#         start_time = time.time()\n",
    "        \n",
    "#         # Initialize convergence checking\n",
    "#         prev_gradients = None\n",
    "#         num_stable_iterations = 0\n",
    "#         convergence_threshold = self.learning_params.get('convergence_threshold', 1e-6)\n",
    "#         min_stable_iterations = self.learning_params.get('min_stable_iterations', 5)\n",
    "        \n",
    "#         for epoch in range(self.learning_params['max_epochs']):\n",
    "#             # Initialize gradient accumulators for the epoch\n",
    "#             epoch_gradients = {t: np.zeros(self.params.N) \n",
    "#                              for t in range(1, self.params.T + 1)}\n",
    "            \n",
    "#             # Compute current learning rate using decay schedule\n",
    "#             learning_rate = max(\n",
    "#                 self.learning_params['eta_min'],\n",
    "#                 self.learning_params['eta_0'] / (1 + self.learning_params['gamma'] * epoch)\n",
    "#             )\n",
    "            \n",
    "#             # Process mini-batch\n",
    "#             for _ in range(self.learning_params['batch_size']):\n",
    "#                 # Generate sample path\n",
    "#                 sample_path = self._generate_sample_path()\n",
    "                \n",
    "#                 # Forward pass through sample path\n",
    "#                 revenues, decision_values, capacities = self._forward_pass(sample_path)\n",
    "                \n",
    "#                 # Backward pass to compute gradients\n",
    "#                 gradients = self._backward_pass(revenues, decision_values, capacities, sample_path)\n",
    "                \n",
    "#                 # Accumulate gradients\n",
    "#                 for t in range(1, self.params.T + 1):\n",
    "#                     epoch_gradients[t] += gradients[t]\n",
    "            \n",
    "#             # Average gradients over mini-batch\n",
    "#             for t in range(1, self.params.T + 1):\n",
    "#                 epoch_gradients[t] /= self.learning_params['batch_size']\n",
    "            \n",
    "#             # Check convergence based on gradient stability\n",
    "#             if prev_gradients is not None:\n",
    "#                 max_gradient_change = max(\n",
    "#                     np.max(np.abs(epoch_gradients[t] - prev_gradients[t]))\n",
    "#                     for t in range(1, self.params.T + 1)\n",
    "#                 )\n",
    "                \n",
    "#                 if max_gradient_change < convergence_threshold:\n",
    "#                     num_stable_iterations += 1\n",
    "#                     if num_stable_iterations >= min_stable_iterations:\n",
    "#                         logger.info(f\"Converged after {epoch + 1} epochs\")\n",
    "#                         break\n",
    "#                 else:\n",
    "#                     num_stable_iterations = 0\n",
    "            \n",
    "#             # Store current gradients for next iteration\n",
    "#             prev_gradients = {t: np.copy(grad) for t, grad in epoch_gradients.items()}\n",
    "            \n",
    "#             # Update prices using averaged gradients\n",
    "#             for t in range(1, self.params.T + 1):\n",
    "#                 self.prices[t] += learning_rate * epoch_gradients[t]\n",
    "#                 # Project prices onto feasible set [price_min, price_max]\n",
    "#                 self.prices[t] = np.clip(self.prices[t], \n",
    "#                                        self.params.price_min,\n",
    "#                                        self.params.price_max)\n",
    "            \n",
    "#             if epoch % 100 == 0:\n",
    "#                 logger.info(f\"Epoch {epoch}: Max Gradient Norm = \"\n",
    "#                           f\"{max(np.linalg.norm(grad) for grad in epoch_gradients.values()):.6f}, \"\n",
    "#                           f\"Learning Rate = {learning_rate:.6f}\")\n",
    "        \n",
    "#         solve_time = time.time() - start_time\n",
    "        \n",
    "#         # Compute final revenue for reporting\n",
    "#         final_revenue = self.evaluate(self.prices)\n",
    "        \n",
    "#         return self.prices, final_revenue, solve_time\n",
    "\n",
    "    def solve(self) -> Tuple[Dict[int, np.ndarray], float, float]:\n",
    "        \"\"\"\n",
    "        Execute the SAA algorithm with proper convergence checking.\n",
    "        \n",
    "        Uses gradient-based convergence criteria and monitors revenue improvements\n",
    "        to determine when the algorithm has converged to an optimal solution.\n",
    "        \n",
    "        Returns:\n",
    "            Tuple of (final_prices, final_revenue, solve_time)\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Initialize convergence monitoring\n",
    "        revenue_history = []\n",
    "        gradient_history = []\n",
    "        window_size = 20  # Window for checking convergence\n",
    "        convergence_tol = 1e-4  # Tolerance for gradient norm\n",
    "        \n",
    "        for epoch in range(self.learning_params['max_epochs']):\n",
    "            # Compute current learning rate using simple decay schedule\n",
    "            learning_rate = max(\n",
    "                self.learning_params['eta_min'],\n",
    "                self.learning_params['eta_0'] / (1 + self.learning_params['gamma'] * epoch)\n",
    "            )\n",
    "            \n",
    "            # Initialize epoch statistics\n",
    "            epoch_gradients = {t: np.zeros(self.params.N) \n",
    "                             for t in range(1, self.params.T + 1)}\n",
    "            epoch_revenue = 0.0\n",
    "            \n",
    "            # Process mini-batch\n",
    "            for _ in range(self.learning_params['batch_size']):\n",
    "                # Generate sample path\n",
    "                sample_path = self._generate_sample_path()\n",
    "                \n",
    "                # Forward pass\n",
    "                revenues, decision_values, capacities = self._forward_pass(sample_path)\n",
    "                \n",
    "                # Backward pass\n",
    "                gradients = self._backward_pass(revenues, decision_values, capacities, sample_path)\n",
    "                \n",
    "                # Accumulate gradients and revenue\n",
    "                for t in range(1, self.params.T + 1):\n",
    "                    epoch_gradients[t] += gradients[t]\n",
    "                epoch_revenue += sum(revenues.values())\n",
    "            \n",
    "            # Average gradients and revenue over mini-batch\n",
    "            for t in range(1, self.params.T + 1):\n",
    "                epoch_gradients[t] /= self.learning_params['batch_size']\n",
    "            avg_revenue = epoch_revenue / self.learning_params['batch_size']\n",
    "            \n",
    "            # Update prices\n",
    "            for t in range(1, self.params.T + 1):\n",
    "                self.prices[t] += learning_rate * epoch_gradients[t]\n",
    "                # Project prices to feasible range\n",
    "                self.prices[t] = np.clip(self.prices[t], \n",
    "                                       self.params.price_min,\n",
    "                                       self.params.price_max)\n",
    "            \n",
    "            # Calculate gradient norm for convergence check\n",
    "            grad_norm = max(np.linalg.norm(grad) for grad in epoch_gradients.values())\n",
    "            gradient_history.append(grad_norm)\n",
    "            revenue_history.append(avg_revenue)\n",
    "            \n",
    "            # Check convergence\n",
    "            if len(gradient_history) >= window_size:\n",
    "                # Keep only the last window_size elements\n",
    "                gradient_history = gradient_history[-window_size:]\n",
    "                revenue_history = revenue_history[-window_size:]\n",
    "                \n",
    "                # Check if gradient norms are consistently small\n",
    "                if all(norm < convergence_tol for norm in gradient_history):\n",
    "                    logger.info(f\"Converged after {epoch + 1} epochs: \"\n",
    "                              f\"gradient norm below tolerance\")\n",
    "                    break\n",
    "                \n",
    "                # Check if revenue has stabilized\n",
    "                revenue_change = abs(revenue_history[-1] - revenue_history[0]) / abs(revenue_history[0])\n",
    "                if revenue_change < convergence_tol and grad_norm < convergence_tol:\n",
    "                    logger.info(f\"Converged after {epoch + 1} epochs: \"\n",
    "                              f\"revenue stabilized and gradient norm small\")\n",
    "                    break\n",
    "            \n",
    "            # Log progress every 50 epochs\n",
    "            if epoch % 100 == 0:\n",
    "                logger.info(f\"Epoch {epoch}: Revenue = {avg_revenue:.2f}, \"\n",
    "                          f\"Gradient Norm = {grad_norm:.6f}, \"\n",
    "                          f\"Learning Rate = {learning_rate:.6f}\")\n",
    "        \n",
    "        solve_time = time.time() - start_time\n",
    "        final_revenue = self.evaluate(self.prices)\n",
    "        \n",
    "        return self.prices, final_revenue, solve_time\n",
    "    \n",
    "    def evaluate(self, prices: Dict[int, np.ndarray], num_samples: int = 1000) -> float:\n",
    "        \"\"\"\n",
    "        Evaluate a pricing policy using Monte Carlo simulation with the original discrete\n",
    "        decision function (not the smoothed version used in training).\n",
    "        \n",
    "        Args:\n",
    "            prices: Dictionary mapping time periods to price vectors\n",
    "            num_samples: Number of sample paths to evaluate\n",
    "            \n",
    "        Returns:\n",
    "            Average revenue across sample paths\n",
    "        \"\"\"\n",
    "        total_revenue = 0.0\n",
    "        \n",
    "        for _ in range(num_samples):\n",
    "            # Generate sample path\n",
    "            sample_path = self._generate_sample_path()\n",
    "            path_revenue = 0.0\n",
    "            capacity = np.full(self.params.N, self.params.C, dtype=np.int32)  # Integer capacity\n",
    "            \n",
    "            # Process each time period\n",
    "            for t, bt, qt in sample_path:\n",
    "                if bt is not None:\n",
    "                    # Extract booking class information\n",
    "                    stay_nights = self.class_stays[bt]\n",
    "                    Lb = self.stay_lengths[bt]\n",
    "                    \n",
    "                    # Check capacity (must have at least 1 room for all nights)\n",
    "                    has_capacity = all(capacity[i] >= 1 for i in stay_nights)\n",
    "                    \n",
    "                    if has_capacity:\n",
    "                        # Compute average price for the stay\n",
    "                        stay_prices = [prices[t][i] for i in stay_nights]\n",
    "                        price_bt = sum(stay_prices) / Lb\n",
    "                        \n",
    "                        # Check if customer accepts price\n",
    "                        if qt >= price_bt:\n",
    "                            # Accept booking\n",
    "                            revenue = Lb * price_bt\n",
    "                            path_revenue += revenue\n",
    "                            \n",
    "                            # Update capacity (integer updates)\n",
    "                            for i in stay_nights:\n",
    "                                capacity[i] -= 1\n",
    "            \n",
    "            total_revenue += path_revenue\n",
    "        \n",
    "        return total_revenue / num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b626ebe0-2c04-48f3-a319-a05349c51ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test instance using data generator\n",
    "config = TestConfiguration()\n",
    "test_params = config.get_config(\n",
    "    test_type='standard',\n",
    "    market_condition='standard',\n",
    "    discretization='standard'\n",
    ")\n",
    "test_instance = create_test_instance(\n",
    "    demand_scenario='base',\n",
    "    market_condition='standard',\n",
    "    test_configuration=test_params\n",
    ")\n",
    "\n",
    "# Configure learning parameters\n",
    "learning_params = {\n",
    "    'eta_0': 0.5,                  # Initial learning rate\n",
    "    'gamma': 0.05,                 # Base decay rate\n",
    "    'eta_min': 0.01,               # Minimum learning rate\n",
    "    'max_epochs': 1000,\n",
    "    'batch_size': 64\n",
    "}\n",
    "\n",
    "# Initialize and run SAA\n",
    "saa = StochasticApproximation(test_instance, learning_params)\n",
    "optimal_prices, expected_revenue, solve_time = saa.solve()\n",
    "print(expected_revenue, solve_time)\n",
    "\n",
    "# Evaluate solution quality\n",
    "final_revenue = saa.evaluate(optimal_prices, num_samples=1000)\n",
    "print(final_revenue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a10721f-8eb9-47d2-9926-f532a38ccbe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51d064e9-f6ac-4533-9540-a4264df8a713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment1(num_trials: int = 5):\n",
    "    \"\"\"\n",
    "    Run Experiment 1: Solution Quality Assessment comparing SAA with DP.\n",
    "    \n",
    "    The experiment uses a small but realistic instance that allows for:\n",
    "    1. Exact solution via Dynamic Programming\n",
    "    2. Multiple trials of SAA to assess consistency\n",
    "    3. Statistical comparison of solution quality\n",
    "    \n",
    "    Args:\n",
    "        num_trials: Number of SAA trials to run for statistical significance\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing detailed experimental results\n",
    "    \"\"\"\n",
    "    logger.info(\"Starting Experiment 1: Solution Quality Assessment\")\n",
    "    \n",
    "    # Create test instance\n",
    "    config = TestConfiguration()\n",
    "    test_params = config.get_config(\n",
    "        test_type='minimal',\n",
    "        market_condition='standard',\n",
    "        discretization='coarse'\n",
    "    )\n",
    "    \n",
    "    # Set parameters for a tractable but meaningful test case\n",
    "    test_params.update({\n",
    "        'T': 10,  # 10 booking periods\n",
    "        'N': 5,   # 5-day service horizon\n",
    "        'C': 5,   # 5 rooms capacity\n",
    "        'price_min': 100,  # Reasonable price range\n",
    "        'price_max': 300,\n",
    "        'alpha': 0.1,     # Smoothing parameters for SAA\n",
    "        'beta': 0.1\n",
    "    })\n",
    "    \n",
    "    # Create instance with fixed seed for reproducibility\n",
    "    instance = create_test_instance(\n",
    "        demand_scenario='base',\n",
    "        market_condition='standard',\n",
    "        test_configuration=test_params,\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    logger.info(\"\\nTest Instance Configuration:\")\n",
    "    logger.info(f\"Booking Horizon (T): {test_params['T']} periods\")\n",
    "    logger.info(f\"Service Horizon (N): {test_params['N']} days\")\n",
    "    logger.info(f\"Room Capacity (C): {test_params['C']} rooms\")\n",
    "    logger.info(f\"Price Range: ${test_params['price_min']} - ${test_params['price_max']}\")\n",
    "    \n",
    "    # Solve using Dynamic Programming\n",
    "    logger.info(\"\\nSolving with Dynamic Programming...\")\n",
    "    dp = DynamicProgramming(instance)\n",
    "    start_time = time.time()\n",
    "    _, dp_revenue = dp.solve()\n",
    "    dp_time = time.time() - start_time\n",
    "    \n",
    "    # Configure SAA parameters\n",
    "    learning_params = {\n",
    "        'eta_0': 0.3,        # Initial learning rate\n",
    "        'gamma': 0.05,       # Learning rate decay\n",
    "        'eta_min': 0.001,    # Minimum learning rate\n",
    "        'max_epochs': 1000,\n",
    "        'batch_size': 64\n",
    "    }\n",
    "    \n",
    "    # Run multiple SAA trials\n",
    "    logger.info(\"\\nSolving with Stochastic Approximation...\")\n",
    "    saa_results = []\n",
    "    \n",
    "    for trial in range(num_trials):\n",
    "        logger.info(f\"\\nSAA Trial {trial + 1}/{num_trials}\")\n",
    "        saa = StochasticApproximation(instance, learning_params)\n",
    "        prices, revenue, solve_time = saa.solve()\n",
    "        \n",
    "        # Evaluate final solution with more samples\n",
    "        final_revenue = saa.evaluate(prices, num_samples=10000)\n",
    "        saa_results.append({\n",
    "            'revenue': final_revenue,\n",
    "            'time': solve_time\n",
    "        })\n",
    "        \n",
    "        logger.info(f\"Trial Revenue: ${final_revenue:.2f}\")\n",
    "        logger.info(f\"Trial Solution Time: {solve_time:.2f} seconds\")\n",
    "    \n",
    "    # Compute SAA statistics\n",
    "    saa_revenues = [r['revenue'] for r in saa_results]\n",
    "    saa_times = [r['time'] for r in saa_results]\n",
    "    \n",
    "    avg_saa_revenue = np.mean(saa_revenues)\n",
    "    std_saa_revenue = np.std(saa_revenues)\n",
    "    avg_saa_time = np.mean(saa_times)\n",
    "    \n",
    "    # Calculate optimality gap\n",
    "    gap_percentage = ((dp_revenue - avg_saa_revenue) / dp_revenue) * 100\n",
    "    \n",
    "    # Compute confidence interval for SAA revenue\n",
    "    confidence_level = 0.95\n",
    "    degrees_of_freedom = num_trials - 1\n",
    "    t_value = stats.t.ppf((1 + confidence_level) / 2, degrees_of_freedom)\n",
    "    margin_of_error = t_value * (std_saa_revenue / np.sqrt(num_trials))\n",
    "    \n",
    "    # Print comprehensive results\n",
    "    logger.info(\"\\nExperiment 1 Results Summary:\")\n",
    "    logger.info(f\"Dynamic Programming Revenue: ${dp_revenue:.2f}\")\n",
    "    logger.info(f\"DP Solution Time: {dp_time:.2f} seconds\")\n",
    "    logger.info(f\"\\nSAA Average Revenue: ${avg_saa_revenue:.2f} ± ${margin_of_error:.2f}\")\n",
    "    logger.info(f\"SAA Revenue Std Dev: ${std_saa_revenue:.2f}\")\n",
    "    logger.info(f\"SAA Average Solution Time: {avg_saa_time:.2f} seconds\")\n",
    "    logger.info(f\"Optimality Gap: {gap_percentage:.2f}%\")\n",
    "    \n",
    "    return {\n",
    "        'dp_revenue': dp_revenue,\n",
    "        'dp_time': dp_time,\n",
    "        'saa_revenues': saa_revenues,\n",
    "        'saa_times': saa_times,\n",
    "        'avg_saa_revenue': avg_saa_revenue,\n",
    "        'std_saa_revenue': std_saa_revenue,\n",
    "        'gap_percentage': gap_percentage,\n",
    "        'confidence_interval': margin_of_error,\n",
    "        'instance_params': test_params,\n",
    "        'learning_params': learning_params\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c248b62-0abb-478f-8b71-9039ce991720",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Starting Experiment 1: Solution Quality Assessment\n",
      "INFO:data_generator:Generated 15 booking classes with max LOS = 7\n",
      "INFO:data_generator:Initialized DataGenerator with 15 booking classes\n",
      "INFO:data_generator:\n",
      "Initial Price Generation Analysis for STANDARD Market\n",
      "INFO:data_generator:Initialization Strategy: MARKET_BASED\n",
      "INFO:data_generator:\n",
      "Overall Price Statistics:\n",
      "INFO:data_generator:Average Price: $193.30\n",
      "INFO:data_generator:Median Price: $191.76\n",
      "INFO:data_generator:Price Range: $153.23 - $279.48\n",
      "INFO:data_generator:Standard Deviation: $30.35\n",
      "INFO:data_generator:\n",
      "Day-of-Week Price Analysis:\n",
      "INFO:data_generator:Sunday: $242.24 (±$20.66)\n",
      "INFO:data_generator:Monday: $177.34 (±$14.06)\n",
      "INFO:data_generator:Tuesday: $175.16 (±$16.85)\n",
      "INFO:data_generator:Wednesday: $174.93 (±$15.23)\n",
      "INFO:data_generator:Thursday: $196.82 (±$11.67)\n",
      "INFO:data_generator:Friday: No data available\n",
      "INFO:data_generator:Saturday: No data available\n",
      "INFO:data_generator:\n",
      "Demand Scenario: base\n",
      "INFO:data_generator:Average daily arrival probability: 0.950\n",
      "INFO:data_generator:Maximum daily arrival probability: 0.950\n",
      "INFO:data_generator:Minimum daily arrival probability: 0.950\n",
      "INFO:data_generator:\n",
      "Average arrival probabilities by day of week:\n",
      "INFO:data_generator:Sunday: 0.074\n",
      "INFO:data_generator:Monday: 0.057\n",
      "INFO:data_generator:Tuesday: 0.057\n",
      "INFO:data_generator:Wednesday: 0.057\n",
      "INFO:data_generator:Thursday: 0.066\n",
      "INFO:data_generator:Friday: 0.000\n",
      "INFO:data_generator:Saturday: 0.000\n",
      "INFO:data_generator:\n",
      "Reservation Price Parameters for STANDARD Market:\n",
      "INFO:data_generator:Market Characteristics:\n",
      "INFO:data_generator:- Base Price Sensitivity: 0.50\n",
      "INFO:data_generator:- Length of Stay Factor: 0.100\n",
      "INFO:data_generator:- Weekend Premium: 0.20\n",
      "INFO:data_generator:- Random Variation: ±0.10\n",
      "INFO:data_generator:\n",
      "Epsilon Statistics:\n",
      "INFO:data_generator:Average epsilon: 0.002701\n",
      "INFO:data_generator:Maximum epsilon: 0.002934\n",
      "INFO:data_generator:Minimum epsilon: 0.002350\n",
      "INFO:data_generator:\n",
      "Average epsilon by length of stay:\n",
      "INFO:data_generator:LOS 1: 0.002493\n",
      "INFO:data_generator:LOS 2: 0.002747\n",
      "INFO:data_generator:LOS 3: 0.002882\n",
      "INFO:data_generator:LOS 4: 0.002780\n",
      "INFO:data_generator:LOS 5: 0.002859\n",
      "INFO:data_generator:\n",
      "Average epsilon by day of week:\n",
      "INFO:data_generator:Sunday: 0.002807\n",
      "INFO:data_generator:Monday: 0.002742\n",
      "INFO:data_generator:Tuesday: 0.002757\n",
      "INFO:data_generator:Wednesday: 0.002773\n",
      "INFO:data_generator:Thursday: 0.002790\n",
      "INFO:data_generator:Friday: 0.000000\n",
      "INFO:data_generator:Saturday: 0.000000\n",
      "INFO:data_generator:\n",
      "Study Instance Generation Summary\n",
      "INFO:data_generator:================================\n",
      "INFO:data_generator:Demand Scenario: base\n",
      "INFO:data_generator:Market Condition: standard\n",
      "INFO:data_generator:Price Initialization Strategy: market_based\n",
      "INFO:data_generator:\n",
      "Instance Dimensions:\n",
      "INFO:data_generator:Booking Horizon (T): 10 periods\n",
      "INFO:data_generator:Service Horizon (N): 5 days\n",
      "INFO:data_generator:Room Capacity (C): 5 rooms\n",
      "INFO:data_generator:Number of Booking Classes: 15\n",
      "INFO:__main__:\n",
      "Test Instance Configuration:\n",
      "INFO:__main__:Booking Horizon (T): 10 periods\n",
      "INFO:__main__:Service Horizon (N): 5 days\n",
      "INFO:__main__:Room Capacity (C): 5 rooms\n",
      "INFO:__main__:Price Range: $100 - $300\n",
      "INFO:__main__:\n",
      "Solving with Dynamic Programming...\n",
      "INFO:__main__:Initialized DP solver with 15 booking classes\n",
      "INFO:__main__:Starting optimized DP solution\n",
      "INFO:__main__:Initializing boundary conditions\n",
      "INFO:__main__:Processed period 10: 7776 states in 20.27 seconds\n",
      "INFO:__main__:Processed period 9: 7776 states in 22.00 seconds\n",
      "INFO:__main__:Processed period 8: 7776 states in 20.44 seconds\n",
      "INFO:__main__:Processed period 7: 7776 states in 21.17 seconds\n",
      "INFO:__main__:Processed period 6: 7776 states in 22.47 seconds\n",
      "INFO:__main__:Processed period 5: 7776 states in 24.52 seconds\n",
      "INFO:__main__:Processed period 4: 7776 states in 25.42 seconds\n",
      "INFO:__main__:Processed period 3: 7776 states in 25.94 seconds\n",
      "INFO:__main__:Processed period 2: 7776 states in 27.13 seconds\n",
      "INFO:__main__:Processed period 1: 7776 states in 28.41 seconds\n",
      "INFO:__main__:DP solution completed in 237.80 seconds. Optimal value: 1780.88\n",
      "INFO:__main__:\n",
      "Solving with Stochastic Approximation...\n",
      "INFO:__main__:\n",
      "SAA Trial 1/5\n",
      "INFO:__main__:Initialized SAA with 15 booking classes\n",
      "INFO:__main__:Epoch 0: Revenue = 532.18, Gradient Norm = 0.119093, Learning Rate = 0.300000\n",
      "INFO:__main__:Epoch 100: Revenue = 551.13, Gradient Norm = 0.115405, Learning Rate = 0.050000\n",
      "INFO:__main__:Epoch 200: Revenue = 536.02, Gradient Norm = 0.112697, Learning Rate = 0.027273\n",
      "INFO:__main__:Epoch 300: Revenue = 538.08, Gradient Norm = 0.103038, Learning Rate = 0.018750\n",
      "INFO:__main__:Epoch 400: Revenue = 517.95, Gradient Norm = 0.107515, Learning Rate = 0.014286\n",
      "INFO:__main__:Epoch 500: Revenue = 526.95, Gradient Norm = 0.113489, Learning Rate = 0.011538\n",
      "INFO:__main__:Epoch 600: Revenue = 503.83, Gradient Norm = 0.094040, Learning Rate = 0.009677\n",
      "INFO:__main__:Epoch 700: Revenue = 541.95, Gradient Norm = 0.112563, Learning Rate = 0.008333\n",
      "INFO:__main__:Epoch 800: Revenue = 546.85, Gradient Norm = 0.093074, Learning Rate = 0.007317\n",
      "INFO:__main__:Epoch 900: Revenue = 549.21, Gradient Norm = 0.153676, Learning Rate = 0.006522\n",
      "INFO:__main__:Trial Revenue: $1764.62\n",
      "INFO:__main__:Trial Solution Time: 34.34 seconds\n",
      "INFO:__main__:\n",
      "SAA Trial 2/5\n",
      "INFO:__main__:Initialized SAA with 15 booking classes\n",
      "INFO:__main__:Epoch 0: Revenue = 537.98, Gradient Norm = 0.111812, Learning Rate = 0.300000\n",
      "INFO:__main__:Epoch 100: Revenue = 520.58, Gradient Norm = 0.090600, Learning Rate = 0.050000\n",
      "INFO:__main__:Epoch 200: Revenue = 529.97, Gradient Norm = 0.102769, Learning Rate = 0.027273\n",
      "INFO:__main__:Epoch 300: Revenue = 534.74, Gradient Norm = 0.129133, Learning Rate = 0.018750\n",
      "INFO:__main__:Epoch 400: Revenue = 550.86, Gradient Norm = 0.160969, Learning Rate = 0.014286\n",
      "INFO:__main__:Epoch 500: Revenue = 581.74, Gradient Norm = 0.121314, Learning Rate = 0.011538\n",
      "INFO:__main__:Epoch 600: Revenue = 498.08, Gradient Norm = 0.101274, Learning Rate = 0.009677\n",
      "INFO:__main__:Epoch 700: Revenue = 527.63, Gradient Norm = 0.154256, Learning Rate = 0.008333\n",
      "INFO:__main__:Epoch 800: Revenue = 523.94, Gradient Norm = 0.130706, Learning Rate = 0.007317\n",
      "INFO:__main__:Epoch 900: Revenue = 526.34, Gradient Norm = 0.113644, Learning Rate = 0.006522\n",
      "INFO:__main__:Trial Revenue: $1767.02\n",
      "INFO:__main__:Trial Solution Time: 34.12 seconds\n",
      "INFO:__main__:\n",
      "SAA Trial 3/5\n",
      "INFO:__main__:Initialized SAA with 15 booking classes\n",
      "INFO:__main__:Epoch 0: Revenue = 524.23, Gradient Norm = 0.123468, Learning Rate = 0.300000\n",
      "INFO:__main__:Epoch 100: Revenue = 535.35, Gradient Norm = 0.174672, Learning Rate = 0.050000\n",
      "INFO:__main__:Epoch 200: Revenue = 549.40, Gradient Norm = 0.164935, Learning Rate = 0.027273\n",
      "INFO:__main__:Epoch 300: Revenue = 560.70, Gradient Norm = 0.106947, Learning Rate = 0.018750\n",
      "INFO:__main__:Epoch 400: Revenue = 529.64, Gradient Norm = 0.098199, Learning Rate = 0.014286\n",
      "INFO:__main__:Epoch 500: Revenue = 530.87, Gradient Norm = 0.108565, Learning Rate = 0.011538\n",
      "INFO:__main__:Epoch 600: Revenue = 550.70, Gradient Norm = 0.091540, Learning Rate = 0.009677\n",
      "INFO:__main__:Epoch 700: Revenue = 507.58, Gradient Norm = 0.088284, Learning Rate = 0.008333\n",
      "INFO:__main__:Epoch 800: Revenue = 548.64, Gradient Norm = 0.173552, Learning Rate = 0.007317\n",
      "INFO:__main__:Epoch 900: Revenue = 532.77, Gradient Norm = 0.110930, Learning Rate = 0.006522\n",
      "INFO:__main__:Trial Revenue: $1770.65\n",
      "INFO:__main__:Trial Solution Time: 34.06 seconds\n",
      "INFO:__main__:\n",
      "SAA Trial 4/5\n",
      "INFO:__main__:Initialized SAA with 15 booking classes\n",
      "INFO:__main__:Epoch 0: Revenue = 522.34, Gradient Norm = 0.088265, Learning Rate = 0.300000\n",
      "INFO:__main__:Epoch 100: Revenue = 541.88, Gradient Norm = 0.123533, Learning Rate = 0.050000\n",
      "INFO:__main__:Epoch 200: Revenue = 532.05, Gradient Norm = 0.151696, Learning Rate = 0.027273\n",
      "INFO:__main__:Epoch 300: Revenue = 511.04, Gradient Norm = 0.099354, Learning Rate = 0.018750\n",
      "INFO:__main__:Epoch 400: Revenue = 539.75, Gradient Norm = 0.154211, Learning Rate = 0.014286\n",
      "INFO:__main__:Epoch 500: Revenue = 525.38, Gradient Norm = 0.143241, Learning Rate = 0.011538\n",
      "INFO:__main__:Epoch 600: Revenue = 521.68, Gradient Norm = 0.127673, Learning Rate = 0.009677\n",
      "INFO:__main__:Epoch 700: Revenue = 538.06, Gradient Norm = 0.124461, Learning Rate = 0.008333\n",
      "INFO:__main__:Epoch 800: Revenue = 534.11, Gradient Norm = 0.183033, Learning Rate = 0.007317\n",
      "INFO:__main__:Epoch 900: Revenue = 525.00, Gradient Norm = 0.127130, Learning Rate = 0.006522\n",
      "INFO:__main__:Trial Revenue: $1765.05\n",
      "INFO:__main__:Trial Solution Time: 34.30 seconds\n",
      "INFO:__main__:\n",
      "SAA Trial 5/5\n",
      "INFO:__main__:Initialized SAA with 15 booking classes\n",
      "INFO:__main__:Epoch 0: Revenue = 548.36, Gradient Norm = 0.132209, Learning Rate = 0.300000\n",
      "INFO:__main__:Epoch 100: Revenue = 501.50, Gradient Norm = 0.103889, Learning Rate = 0.050000\n",
      "INFO:__main__:Epoch 200: Revenue = 548.30, Gradient Norm = 0.101445, Learning Rate = 0.027273\n",
      "INFO:__main__:Epoch 300: Revenue = 563.88, Gradient Norm = 0.112886, Learning Rate = 0.018750\n",
      "INFO:__main__:Epoch 400: Revenue = 544.96, Gradient Norm = 0.089096, Learning Rate = 0.014286\n",
      "INFO:__main__:Epoch 500: Revenue = 562.84, Gradient Norm = 0.094436, Learning Rate = 0.011538\n",
      "INFO:__main__:Epoch 600: Revenue = 585.47, Gradient Norm = 0.118778, Learning Rate = 0.009677\n",
      "INFO:__main__:Epoch 700: Revenue = 497.96, Gradient Norm = 0.130422, Learning Rate = 0.008333\n",
      "INFO:__main__:Epoch 800: Revenue = 524.06, Gradient Norm = 0.099496, Learning Rate = 0.007317\n",
      "INFO:__main__:Epoch 900: Revenue = 514.87, Gradient Norm = 0.111240, Learning Rate = 0.006522\n",
      "INFO:__main__:Trial Revenue: $1768.16\n",
      "INFO:__main__:Trial Solution Time: 33.73 seconds\n",
      "INFO:__main__:\n",
      "Experiment 1 Results Summary:\n",
      "INFO:__main__:Dynamic Programming Revenue: $1780.88\n",
      "INFO:__main__:DP Solution Time: 237.80 seconds\n",
      "INFO:__main__:\n",
      "SAA Average Revenue: $1767.10 ± $2.72\n",
      "INFO:__main__:SAA Revenue Std Dev: $2.19\n",
      "INFO:__main__:SAA Average Solution Time: 34.11 seconds\n",
      "INFO:__main__:Optimality Gap: 0.77%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    results = run_experiment1(num_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7481b3-455b-4759-a3ad-bf79006b8c8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9644acf1-a24e-4656-a5b9-a66c740938b6",
   "metadata": {},
   "source": [
    "# Run Experiment with Hand Calculated Solution for DP in Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959bd65c-075e-41fd-b261-23c4c7152826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment1():\n",
    "    \"\"\"Run Experiment 1: Solution Quality Assessment.\"\"\"\n",
    "    logger.info(\"Starting Experiment 1: Solution Quality Assessment\")\n",
    "    \n",
    "    # Create test instance\n",
    "    config = TestConfiguration()\n",
    "    test_params = config.get_config(\n",
    "        test_type='minimal',\n",
    "        market_condition='standard',\n",
    "        discretization='coarse'\n",
    "    )\n",
    "    \n",
    "    # Override parameters for small instance\n",
    "    test_params.update({\n",
    "        'T': 10,  # Small booking horizon\n",
    "        'N': 5,   # Small service horizon\n",
    "        'C': 5    # Small capacity\n",
    "    })\n",
    "    \n",
    "    instance = create_test_instance(\n",
    "        demand_scenario='base',\n",
    "        market_condition='standard',\n",
    "        test_configuration=test_params,\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    # Solve using Dynamic Programming\n",
    "    dp = DynamicProgramming(instance)\n",
    "    dp_revenue, dp_time = dp.solve()\n",
    "    \n",
    "    # Solve using Stochastic Approximation\n",
    "    saa = StochasticApproximation(instance)\n",
    "    saa_revenue, saa_time = saa.solve()\n",
    "    \n",
    "    # Calculate gap\n",
    "    gap_percentage = ((dp_revenue - saa_revenue) / dp_revenue) * 100\n",
    "    \n",
    "    # Print results\n",
    "    logger.info(\"\\nExperiment 1 Results:\")\n",
    "    logger.info(f\"Dynamic Programming Revenue: ${dp_revenue:.2f}\")\n",
    "    logger.info(f\"SAA Revenue: ${saa_revenue:.2f}\")\n",
    "    logger.info(f\"Optimality Gap: {gap_percentage:.2f}%\")\n",
    "    logger.info(f\"DP Solution Time: {dp_time:.2f} seconds\")\n",
    "    logger.info(f\"SAA Solution Time: {saa_time:.2f} seconds\")\n",
    "    \n",
    "    return {\n",
    "        'dp_revenue': dp_revenue,\n",
    "        'saa_revenue': saa_revenue,\n",
    "        'gap_percentage': gap_percentage,\n",
    "        'dp_time': dp_time,\n",
    "        'saa_time': saa_time\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d5b2d5-78e8-4541-8e8a-922bfa011e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    results = run_experiment1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8451b504-44f4-4394-ad7e-c82e93bdecc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
