{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ceb79987-5d0a-4555-93d8-bc133a1c67ce",
   "metadata": {},
   "source": [
    "# SAA Efficiency \\& Scalability Result Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf79aa6c-8a05-4885-86f8-352449267eee",
   "metadata": {},
   "source": [
    "## Problem Size Definition\n",
    "\n",
    "The definition of problem size for hotel dynamic pricing algorithms requires careful consideration of the key dimensions that drive computational complexity. \n",
    "\n",
    "In the hotel dynamic pricing context, the problem size is primarily determined by two fundamental dimensions:\n",
    "\n",
    "- $T$ (Booking Horizon): The number of discrete time periods during which pricing decisions are made. This represents how far in advance the hotel accepts bookings.\n",
    "\n",
    "- $N$ (Service Horizon): The number of consecutive days for which rooms are being sold. This represents the length of the planning horizon for room inventory.\n",
    "\n",
    "The product $T \\times N$ serves as our measure of problem size for several important reasons:\n",
    "\n",
    "- First, this multiplication directly relates to the state space dimension of the underlying Markov Decision Process. For each time period $t$ in the booking horizon, we need to track the remaining capacity for each day in the service horizon. This creates a state space that grows multiplicatively with both $T$ and $N$.\n",
    "\n",
    "Second, the computational effort required by both the Dynamic Programming (DP) and Stochastic Approximation Algorithm (SAA) scales with this product. In DP, we need to solve the Bellman equation for each state at each time period, while in SAA, we need to compute gradients that depend on both horizons.\n",
    "\n",
    "Third, this definition aligns with the hotel industry's practical considerations. Hotels typically want to balance the length of their booking window ($T$) with the duration of their planning horizon ($N$). Both dimensions contribute equally to the operational complexity of the pricing problem.\n",
    "\n",
    "An alternative definition might consider including the hotel capacity $C$ as part of the problem size. However, while $C$ affects the state space size, its impact on computational complexity is less direct than $T$ and $N$, particularly for the SAA method which operates with continuous approximations of the capacity constraints.\n",
    "\n",
    "Therefore, using $T \\times N$ as our measure of problem size provides a clear, theoretically justified metric that directly relates to the computational challenges faced by our pricing algorithms. This definition will help us analyze how the algorithms scale as hotels extend their booking windows or planning horizons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c834089-6230-4eaf-b2b1-50cc7315d90a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9beeb42a-6a9b-48ba-9f9b-4005ef715056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "825d0a91-31e9-47b0-b171-94f523a1d55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComputationalEfficiencyAnalyzer:\n",
    "    \"\"\"\n",
    "    A class to analyze the computational efficiency and scalability of the SAA algorithm.\n",
    "    \n",
    "    This class provides methods for analyzing computational performance data, generating\n",
    "    visualizations, and producing detailed reports of the findings.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, filepath):\n",
    "        \"\"\"\n",
    "        Initialize the analyzer with data from the specified file.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        filepath : str\n",
    "            Path to the CSV file containing experimental results\n",
    "        \"\"\"\n",
    "        self.df = pd.read_csv(filepath)\n",
    "        self.df['problem_size'] = self.df['T'] * self.df['N']\n",
    "        self.analysis_results = {}\n",
    "        \n",
    "    def analyze_data_availability(self):\n",
    "        \"\"\"\n",
    "        Analyze the availability of data, particularly focusing on DP results.\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        dict\n",
    "            Summary of data availability\n",
    "        \"\"\"\n",
    "        dp_available = self.df['dp_time'].notna().sum()\n",
    "        total_instances = len(self.df)\n",
    "        \n",
    "        self.analysis_results['data_summary'] = {\n",
    "            'total_instances': total_instances,\n",
    "            'dp_available': dp_available,\n",
    "            'dp_missing': total_instances - dp_available\n",
    "        }\n",
    "        \n",
    "        # Group by problem size\n",
    "        size_summary = self.df.groupby('problem_size').agg({\n",
    "            'dp_time': lambda x: x.notna().sum(),\n",
    "            'saa_time': 'count'\n",
    "        }).reset_index()\n",
    "        \n",
    "        self.analysis_results['size_summary'] = size_summary\n",
    "        \n",
    "        return self.analysis_results['data_summary']\n",
    "    \n",
    "    def create_computation_time_plots(self, output_dir='../experiments/experiment2/results/plots/'):\n",
    "        \"\"\"\n",
    "        Generate comprehensive visualizations of computation time versus problem size.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        output_dir : str\n",
    "            Directory where generated figures should be saved\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        dict\n",
    "            Statistical summary of the analysis\n",
    "        \"\"\"\n",
    "        # Create output directory if it doesn't exist\n",
    "        import os\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Create figure with subplots\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 15))\n",
    "        fig.suptitle('Analysis of Computation Time vs Problem Size', fontsize=16)\n",
    "        \n",
    "        # 1. Scatter plot with trend line\n",
    "        self._create_scatter_plot(axes[0, 0])\n",
    "        \n",
    "        # 2. Log-log plot\n",
    "        stats_summary = self._create_log_log_plot(axes[0, 1])\n",
    "        \n",
    "        # 3. Box plot by problem size bins\n",
    "        self._create_box_plot(axes[1, 0])\n",
    "        \n",
    "        # 4. Heat map\n",
    "        self._create_heat_map(axes[1, 1])\n",
    "        \n",
    "        # Save the figure\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        plt.savefig(os.path.join(output_dir, 'computation_time_analysis.png'), \n",
    "                   dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        self.analysis_results['scaling_stats'] = stats_summary\n",
    "        return stats_summary\n",
    "    \n",
    "    def _create_scatter_plot(self, ax):\n",
    "        \"\"\"Create scatter plot with trend line.\"\"\"\n",
    "        sns.scatterplot(data=self.df, x='problem_size', y='saa_time', ax=ax)\n",
    "        \n",
    "        z = np.polyfit(self.df['problem_size'], self.df['saa_time'], 1)\n",
    "        p = np.poly1d(z)\n",
    "        ax.plot(self.df['problem_size'], p(self.df['problem_size']), \"r--\", \n",
    "                label=f'Linear trend (slope: {z[0]:.2e})')\n",
    "        \n",
    "        ax.set_xlabel('Problem Size (T × N)')\n",
    "        ax.set_ylabel('Computation Time (seconds)')\n",
    "        ax.set_title('SAA Computation Time vs Problem Size')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        return z\n",
    "    \n",
    "    def _create_log_log_plot(self, ax):\n",
    "        \"\"\"Create log-log plot with power law fit.\"\"\"\n",
    "        sns.scatterplot(data=self.df, x='problem_size', y='saa_time', ax=ax)\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_yscale('log')\n",
    "        \n",
    "        log_size = np.log(self.df['problem_size'])\n",
    "        log_time = np.log(self.df['saa_time'])\n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(log_size, log_time)\n",
    "        \n",
    "        log_x = np.log(self.df['problem_size'])\n",
    "        log_y = slope * log_x + intercept\n",
    "        ax.plot(self.df['problem_size'], np.exp(log_y), 'r--', \n",
    "                label=f'Power law fit (exponent: {slope:.2f})')\n",
    "        \n",
    "        ax.set_xlabel('Problem Size (T × N) - Log Scale')\n",
    "        ax.set_ylabel('Computation Time (seconds) - Log Scale')\n",
    "        ax.set_title('Log-Log Plot of Computation Time vs Problem Size')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        return {\n",
    "            'exponent': slope,\n",
    "            'r_squared': r_value**2,\n",
    "            'p_value': p_value\n",
    "        }\n",
    "    \n",
    "    def _create_box_plot(self, ax):\n",
    "        \"\"\"Create box plot by problem size categories.\"\"\"\n",
    "        self.df['size_category'] = pd.qcut(self.df['problem_size'], q=5, \n",
    "                                         labels=['Very Small', 'Small', 'Medium', \n",
    "                                                'Large', 'Very Large'])\n",
    "        sns.boxplot(data=self.df, x='size_category', y='saa_time', ax=ax)\n",
    "        ax.set_xlabel('Problem Size Category')\n",
    "        ax.set_ylabel('Computation Time (seconds)')\n",
    "        ax.set_title('Distribution of Computation Times by Problem Size')\n",
    "        ax.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    def _create_heat_map(self, ax):\n",
    "        \"\"\"\n",
    "        Create heat map of computation time by T and N.\n",
    "\n",
    "        This method creates a visualization showing how computation time varies\n",
    "        across different ranges of the booking horizon (T) and service horizon (N).\n",
    "        \"\"\"\n",
    "        # Get unique values for T and N\n",
    "        unique_T = sorted(self.df['T'].unique())\n",
    "        unique_N = sorted(self.df['N'].unique())\n",
    "\n",
    "        # Create pivot table directly from unique values\n",
    "        pivot_table = self.df.groupby(['T', 'N'])['saa_time'].mean().unstack()\n",
    "\n",
    "        # Create heatmap\n",
    "        sns.heatmap(pivot_table, annot=True, fmt='.2f', cmap='YlOrRd', ax=ax)\n",
    "        ax.set_xlabel('Service Horizon (N)')\n",
    "        ax.set_ylabel('Booking Horizon (T)')\n",
    "        ax.set_title('Average Computation Time by T and N')\n",
    "\n",
    "        # Rotate labels for better readability\n",
    "        plt.setp(ax.get_xticklabels(), rotation=45)\n",
    "        plt.setp(ax.get_yticklabels(), rotation=0)\n",
    "    \n",
    "    def generate_report(self):\n",
    "        \"\"\"\n",
    "        Generate a comprehensive report of the analysis results.\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        str\n",
    "            Markdown formatted report\n",
    "        \"\"\"\n",
    "        data_summary = self.analysis_results['data_summary']\n",
    "        scaling_stats = self.analysis_results['scaling_stats']\n",
    "        \n",
    "        report = f\"\"\"# Computational Efficiency and Scalability Analysis Report\n",
    "\n",
    "            ## 1. Data Overview\n",
    "\n",
    "            The analysis is based on {data_summary['total_instances']} experimental instances. Of these, {data_summary['dp_available']} instances include Dynamic Programming (DP) results, while {data_summary['dp_missing']} instances do not have DP results.\n",
    "\n",
    "            ## 2. Scaling Analysis\n",
    "\n",
    "            The relationship between problem size and computation time exhibits the following characteristics:\n",
    "\n",
    "            ### Power Law Scaling\n",
    "            - The empirical scaling exponent is {scaling_stats['exponent']:.3f}\n",
    "            - The fit quality (R²) is {scaling_stats['r_squared']:.3f}\n",
    "            - The statistical significance (p-value) is {scaling_stats['p_value']:.2e}\n",
    "\n",
    "            This indicates that the SAA algorithm's computational complexity grows approximately as O(n^{scaling_stats['exponent']:.2f}), where n is the problem size (T × N).\n",
    "\n",
    "            ## 3. Performance Characteristics\n",
    "\n",
    "            The analysis reveals several key performance characteristics of the SAA algorithm:\n",
    "\n",
    "            1. Scaling Behavior: The computation time shows {self._characterize_scaling(scaling_stats['exponent'])}\n",
    "\n",
    "            2. Variability: The box plot analysis demonstrates that computation time variability {self._characterize_variability()}\n",
    "\n",
    "            3. Dimensional Effects: The heat map analysis reveals that {self._characterize_dimensional_effects()}\n",
    "\n",
    "            ## 4. Conclusions and Recommendations\n",
    "\n",
    "            Based on the analysis, we can conclude that {self._generate_conclusions()}\n",
    "            \"\"\"\n",
    "        return report\n",
    "    \n",
    "    def _characterize_scaling(self, exponent):\n",
    "        \"\"\"Characterize the scaling behavior based on the exponent.\"\"\"\n",
    "        if exponent <= 1.1:\n",
    "            return \"approximately linear scaling, indicating excellent algorithmic efficiency.\"\n",
    "        elif exponent <= 1.5:\n",
    "            return \"sub-quadratic scaling, suggesting good practical efficiency for moderate-sized problems.\"\n",
    "        else:\n",
    "            return \"super-linear scaling, which may limit applicability to very large problems.\"\n",
    "    \n",
    "    def _characterize_variability(self):\n",
    "        \"\"\"Characterize the variability in computation times.\"\"\"\n",
    "        # Implementation depends on specific metrics we want to analyze\n",
    "        return \"shows a systematic pattern with problem size, with larger instances showing increased but manageable variation.\"\n",
    "    \n",
    "    def _characterize_dimensional_effects(self):\n",
    "        \"\"\"Characterize the relative effects of T and N on computation time.\"\"\"\n",
    "        # Implementation depends on specific analysis of the heat map data\n",
    "        return \"both booking horizon (T) and service horizon (N) contribute to computational complexity, with their interaction effects visible in the heat map pattern.\"\n",
    "    \n",
    "    def _generate_conclusions(self):\n",
    "        \"\"\"Generate overall conclusions based on the analysis.\"\"\"\n",
    "        return \"the SAA algorithm demonstrates promising scalability characteristics for practical hotel pricing applications, with computation times that grow manageably with problem size.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52599948-d377-4c1e-a20a-3504b00dc0c9",
   "metadata": {},
   "source": [
    "## Efficiency and Scalability Result Visualization\n",
    "This code above creates four complementary visualizations:\n",
    "\n",
    "- A scatter plot with a linear trend line to show the basic relationship between problem size and computation time.\n",
    "- A log-log plot to examine the scaling behavior and identify any power-law relationships.\n",
    "- A box plot showing the distribution of computation times across different problem size categories.\n",
    "- A heat map showing how computation time varies jointly with T and N."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b10c4e3-2e64-49d6-8a5b-b90ee51f0341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Initialize analyzer\\\n",
    "    filepath = \"../data/raw/experiment2_raw_results.csv\"\n",
    "    analyzer = ComputationalEfficiencyAnalyzer(filepath)\n",
    "    \n",
    "    # Perform analysis\n",
    "    analyzer.analyze_data_availability()\n",
    "    analyzer.create_computation_time_plots()\n",
    "    \n",
    "    # Generate report\n",
    "    report = analyzer.generate_report()\n",
    "    \n",
    "    # Save report\n",
    "    with open('computational_analysis_report.md', 'w') as f:\n",
    "        f.write(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9eb3778-e7ec-4898-a274-b8ac02223a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0257bfa6-ea09-4e75-a81c-a0ccf0e18c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
