{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac825d2d-87f2-42fa-92c5-22b7aa1eafa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List, Tuple\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import itertools\n",
    "import time\n",
    "from data_generator import TestConfiguration, create_test_instance\n",
    "from dynamic_pricing_algorithms import DynamicProgramming, StochasticApproximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f627b5c4-a6c3-46f7-802e-6239f531350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f1e69f-d8e8-469e-904f-bf844becac05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScalabilityExperiment:\n",
    "    \"\"\"\n",
    "    Implementation of Experiment 2: Computational Efficiency and Scalability\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, base_results_dir: str = \"../experiments/experiment2\"):\n",
    "        \"\"\"Initialize experiment parameters and directories.\"\"\"\n",
    "        # Set up results directory\n",
    "        self.base_results_dir = Path(base_results_dir)\n",
    "        self.output_dir = self.base_results_dir / \"results\"\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Define property configurations\n",
    "        self.property_configs = [\n",
    "            {\n",
    "                'type': 'boutique',\n",
    "                'capacity': 50,\n",
    "                'booking_horizons': [28, 56, 84],\n",
    "                'service_horizons': [7, 14, 28]\n",
    "            },\n",
    "            {\n",
    "                'type': 'mid_size',\n",
    "                'capacity': 150,\n",
    "                'booking_horizons': [56, 84, 168],\n",
    "                'service_horizons': [14, 28, 84]\n",
    "            },\n",
    "            {\n",
    "                'type': 'large',\n",
    "                'capacity': 300,\n",
    "                'booking_horizons': [84, 168, 336],\n",
    "                'service_horizons': [28, 84]\n",
    "            },\n",
    "            {\n",
    "                'type': 'resort_chain',\n",
    "                'capacity': 600,\n",
    "                'booking_horizons': [168, 336],\n",
    "                'service_horizons': [28, 84]\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # Generate test cases from property configurations\n",
    "        self.test_cases = self._generate_test_cases()\n",
    "        \n",
    "        # Fixed parameters\n",
    "        self.market_condition = 'standard'\n",
    "        self.demand_scenario = 'base'\n",
    "        \n",
    "        # SAA learning parameters\n",
    "        self.learning_params = {\n",
    "            'eta_0': 0.3,\n",
    "            'gamma': 0.05,\n",
    "            'eta_min': 0.001,\n",
    "            'max_epochs': 1000,\n",
    "            'batch_size': 64\n",
    "        }\n",
    "        \n",
    "        # Experiment parameters\n",
    "        self.num_replications = 5\n",
    "        self.dp_size_limit = 1000\n",
    "        \n",
    "        logger.info(f\"Initialized ScalabilityExperiment with {len(self.test_cases)} test cases\")\n",
    "        \n",
    "    def _generate_test_cases(self) -> List[Dict]:\n",
    "        \"\"\"Generate all test cases from property configurations.\"\"\"\n",
    "        test_cases = []\n",
    "        for config in self.property_configs:\n",
    "            for T in config['booking_horizons']:\n",
    "                for N in config['service_horizons']:\n",
    "                    test_case = {\n",
    "                        'property_type': config['type'],\n",
    "                        'capacity': config['capacity'],\n",
    "                        'T': T,\n",
    "                        'N': N\n",
    "                    }\n",
    "                    test_cases.append(test_case)\n",
    "        return test_cases\n",
    "        \n",
    "    def generate_test_instance(self, test_case: Dict, seed: int) -> Dict:\n",
    "        \"\"\"Generate a test instance with specified parameters.\"\"\"\n",
    "        config = TestConfiguration()\n",
    "        test_params = config.get_config(\n",
    "            test_type='minimal',\n",
    "            market_condition=self.market_condition,\n",
    "            discretization='standard'\n",
    "        )\n",
    "        \n",
    "        # Override with experiment-specific parameters\n",
    "        test_params.update({\n",
    "            'T': test_case['T'],\n",
    "            'N': test_case['N'],\n",
    "            'C': test_case['capacity']\n",
    "        })\n",
    "        \n",
    "        return create_test_instance(\n",
    "            demand_scenario=self.demand_scenario,\n",
    "            market_condition=self.market_condition,\n",
    "            test_configuration=test_params,\n",
    "            seed=seed\n",
    "        )\n",
    "        \n",
    "    def run_single_instance(self, test_case: Dict, replication: int) -> Dict:\n",
    "        \"\"\"Run algorithms on a single test instance.\"\"\"\n",
    "        try:\n",
    "            logger.debug(f\"Processing test case: {test_case}, replication: {replication}\")\n",
    "            \n",
    "            # Generate test instance\n",
    "            instance = self.generate_test_instance(test_case, seed=1000 * replication)\n",
    "            \n",
    "            # Initialize results dictionary with test case parameters\n",
    "            results = {\n",
    "                **test_case,  # Include all test case parameters\n",
    "                'replication': replication,\n",
    "                'state_space_size': test_case['capacity'] ** test_case['N']\n",
    "            }\n",
    "            \n",
    "            # Run SAA\n",
    "            saa = StochasticApproximation(instance, self.learning_params)\n",
    "            saa_start = time.time()\n",
    "            saa_prices, saa_revenue, saa_time = saa.solve()\n",
    "            results['saa_time'] = saa_time\n",
    "            results['saa_revenue'] = saa_revenue\n",
    "            \n",
    "            # Run DP only if state space is manageable\n",
    "            if results['state_space_size'] <= self.dp_size_limit:\n",
    "                dp = DynamicProgramming(instance)\n",
    "                dp_start = time.time()\n",
    "                dp_policy, dp_value = dp.solve()\n",
    "                results['dp_time'] = time.time() - dp_start\n",
    "                results['dp_revenue'] = dp_value\n",
    "            else:\n",
    "                results['dp_time'] = None\n",
    "                results['dp_revenue'] = None\n",
    "            \n",
    "            logger.debug(f\"Completed test case: {test_case}, replication: {replication}\")\n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing test case {test_case}, replication {replication}: {str(e)}\")\n",
    "            raise\n",
    "            \n",
    "    def run_experiment(self, num_workers: int = 4) -> pd.DataFrame:\n",
    "        \"\"\"Run the complete scalability experiment.\"\"\"\n",
    "        logger.info(\"Starting scalability experiment\")\n",
    "        \n",
    "        # Generate replication cases\n",
    "        all_test_cases = []\n",
    "        for test_case in self.test_cases:\n",
    "            for r in range(self.num_replications):\n",
    "                case = {**test_case, 'replication': r}\n",
    "                all_test_cases.append(case)\n",
    "                \n",
    "        logger.info(f\"Generated {len(all_test_cases)} total test cases with replications\")\n",
    "        \n",
    "        # Run experiments in parallel\n",
    "        results = []\n",
    "        with ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "            future_to_case = {\n",
    "                executor.submit(\n",
    "                    self.run_single_instance,\n",
    "                    case,\n",
    "                    case['replication']\n",
    "                ): case for case in all_test_cases\n",
    "            }\n",
    "            \n",
    "            for future in future_to_case:\n",
    "                try:\n",
    "                    result = future.result()\n",
    "                    if result is not None:\n",
    "                        results.append(result)\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error in parallel execution: {str(e)}\")\n",
    "                    continue\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        results_df = pd.DataFrame(results)\n",
    "        \n",
    "        # Save raw results\n",
    "        results_df.to_csv(self.output_dir / 'raw_results.csv', index=False)\n",
    "        logger.info(f\"Completed experiment with {len(results_df)} successful test cases\")\n",
    "        \n",
    "        return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5937ca-6d7a-4025-addf-457d73519dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_scalability_experiment():\n",
    "    \"\"\"Test the ScalabilityExperiment implementation.\"\"\"\n",
    "    # Initialize experiment\n",
    "    experiment = ScalabilityExperiment()\n",
    "    \n",
    "    # Verify test case generation\n",
    "    assert len(experiment.test_cases) > 0, \"Test cases should be generated\"\n",
    "    test_case = experiment.test_cases[0]\n",
    "    assert all(k in test_case for k in ['property_type', 'capacity', 'T', 'N']), \\\n",
    "        \"Test case should contain all required parameters\"\n",
    "    \n",
    "    # Test single instance execution\n",
    "    result = experiment.run_single_instance(test_case, replication=0)\n",
    "    assert result is not None, \"Single instance execution should succeed\"\n",
    "    assert all(k in result for k in ['saa_time', 'saa_revenue']), \\\n",
    "        \"Result should contain algorithm metrics\"\n",
    "    \n",
    "    # Test full experiment execution with minimal replications\n",
    "    experiment.num_replications = 1  # Minimize test time\n",
    "    results_df = experiment.run_experiment(num_workers=1)\n",
    "    assert len(results_df) > 0, \"Experiment should produce results\"\n",
    "    assert 'property_type' in results_df.columns, \"Results should contain property type\"\n",
    "    assert 'capacity' in results_df.columns, \"Results should contain capacity\"\n",
    "    \n",
    "    print(\"All tests passed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee22c5f2-5d03-4239-9bfa-3bed46be632d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    test_scalability_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2520f857-ae0b-4403-bd3a-10dcf6737f27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
